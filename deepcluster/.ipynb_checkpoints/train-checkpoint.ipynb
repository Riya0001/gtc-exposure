{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import faiss\n",
    "except ImportError:\n",
    "    # esnure you are using this version due to a object depreciation that means \\\n",
    "    # the clustering does not run on the newer version\n",
    "    !pip3 install faiss-gpu==1.6.1\n",
    "    import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#may have to compile pytorch with cuda in terminal with:\n",
    "# conda install -c pytorch torchvision cudatoolkit=10.1 pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR=\"/home/jovyan/gtc-exposure/data/\"\n",
    "ARCH=\"vgg16\"\n",
    "#LR=0.05\n",
    "LR=0.01\n",
    "K=6\n",
    "EPOCHS = 20\n",
    "EXP='/home/jovyan/gtc-exposure/deepcluster/output/'\n",
    "\n",
    "#make output directory:\n",
    "#!mkdir -p ${EXP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: vgg16\n",
      "Load dataset: 1.57 s\n",
      "Compute features\n",
      "0 / 952\tTime: 1.575 (1.575)\n",
      "200 / 952\tTime: 0.019 (0.026)\n",
      "400 / 952\tTime: 0.019 (0.023)\n",
      "600 / 952\tTime: 0.019 (0.021)\n",
      "800 / 952\tTime: 0.019 (0.021)\n",
      "Cluster the features\n",
      "k-means loss evolution: [3151.413  1820.5631 1806.2076 1789.3501 1775.169  1771.8215 1770.4752\n",
      " 1769.3129 1768.2358 1767.454  1766.8153 1766.2637 1766.0189 1765.7787\n",
      " 1765.5105 1765.2892 1765.046  1764.8702 1764.7617 1764.6022]\n",
      "k-means time: 14 s\n",
      "Assign pseudo labels\n",
      "Save checkpoint at: /home/jovyan/gtc-exposure/deepcluster/output/checkpoints/checkpoint_0.0.pth.tar\n",
      "Epoch: [0][0/952]\tTime: 6.865 (6.865)\tData: 0.504 (0.504)\tLoss: 1.6777 (1.6777)\n",
      "Epoch: [0][200/952]\tTime: 0.081 (0.114)\tData: 0.000 (0.003)\tLoss: 1.5701 (2.6730)\n",
      "Epoch: [0][400/952]\tTime: 0.081 (0.097)\tData: 0.000 (0.001)\tLoss: 1.8146 (3.5779)\n",
      "Epoch: [0][600/952]\tTime: 0.081 (0.092)\tData: 0.000 (0.001)\tLoss: 1.8321 (2.9948)\n",
      "Epoch: [0][800/952]\tTime: 0.080 (0.089)\tData: 0.000 (0.001)\tLoss: 1.6445 (2.6919)\n",
      "###### Epoch [0] ###### \n",
      "Time: 83.540 s\n",
      "Clustering loss: 1764.602 \n",
      "ConvNet loss: 2.546\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.529 (0.529)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.017 (0.019)\n",
      "600 / 952\tTime: 0.019 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2498.4348 1515.2787 1484.5065 1475.6289 1470.4565 1467.206  1464.8854\n",
      " 1462.8937 1461.3212 1460.1072 1459.2653 1458.1532 1456.86   1455.735\n",
      " 1455.1069 1454.7568 1453.9613 1453.243  1452.4786 1451.6779]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [1][0/952]\tTime: 0.569 (0.569)\tData: 0.533 (0.533)\tLoss: 1.8013 (1.8013)\n",
      "Epoch: [1][200/952]\tTime: 0.080 (0.083)\tData: 0.000 (0.003)\tLoss: 2.5056 (1.7288)\n",
      "Epoch: [1][400/952]\tTime: 0.082 (0.082)\tData: 0.000 (0.001)\tLoss: 2.0059 (1.7311)\n",
      "Epoch: [1][600/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 1.2431 (1.7061)\n",
      "Epoch: [1][800/952]\tTime: 0.079 (0.081)\tData: 0.000 (0.001)\tLoss: 1.0457 (1.6923)\n",
      "###### Epoch [1] ###### \n",
      "Time: 77.243 s\n",
      "Clustering loss: 1451.678 \n",
      "ConvNet loss: 1.680\n",
      "NMI against previous assignment: 0.098\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.533 (0.533)\n",
      "200 / 952\tTime: 0.018 (0.020)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2387.3481 1399.0695 1373.6357 1364.8289 1360.6375 1358.9124 1357.4347\n",
      " 1354.9823 1352.6637 1349.6234 1346.8922 1346.067  1345.7705 1345.5911\n",
      " 1345.5294 1345.5049 1345.4915 1345.4794 1345.4794 1345.4794]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [2][0/952]\tTime: 0.530 (0.530)\tData: 0.476 (0.476)\tLoss: 1.7822 (1.7822)\n",
      "Epoch: [2][200/952]\tTime: 0.081 (0.084)\tData: 0.000 (0.002)\tLoss: 1.5428 (1.6968)\n",
      "Epoch: [2][400/952]\tTime: 0.082 (0.082)\tData: 0.000 (0.001)\tLoss: 1.5965 (1.7031)\n",
      "Epoch: [2][600/952]\tTime: 0.079 (0.082)\tData: 0.000 (0.001)\tLoss: 1.4965 (1.6937)\n",
      "Epoch: [2][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 2.1088 (1.6860)\n",
      "###### Epoch [2] ###### \n",
      "Time: 77.239 s\n",
      "Clustering loss: 1345.479 \n",
      "ConvNet loss: 1.681\n",
      "NMI against previous assignment: 0.239\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.559 (0.559)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.019 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2401.2305 1264.9805 1217.854  1208.6792 1205.0048 1203.1843 1201.7347\n",
      " 1200.1509 1197.706  1195.0889 1193.2328 1191.682  1190.4996 1189.8937\n",
      " 1189.4456 1188.8112 1188.0874 1187.5355 1187.0356 1186.6477]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [3][0/952]\tTime: 0.538 (0.538)\tData: 0.484 (0.484)\tLoss: 1.7774 (1.7774)\n",
      "Epoch: [3][200/952]\tTime: 0.082 (0.083)\tData: 0.000 (0.003)\tLoss: 1.3976 (1.6579)\n",
      "Epoch: [3][400/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 0.6807 (1.6018)\n",
      "Epoch: [3][600/952]\tTime: 0.079 (0.082)\tData: 0.000 (0.001)\tLoss: 2.2559 (1.5719)\n",
      "Epoch: [3][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 2.2308 (1.5590)\n",
      "###### Epoch [3] ###### \n",
      "Time: 77.231 s\n",
      "Clustering loss: 1186.648 \n",
      "ConvNet loss: 1.552\n",
      "NMI against previous assignment: 0.382\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.572 (0.572)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.019 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2521.5605 1499.6511 1471.5269 1463.2084 1459.2513 1456.7693 1454.7722\n",
      " 1451.0586 1445.9724 1439.49   1432.2592 1430.3627 1429.7347 1429.373\n",
      " 1428.9207 1428.7632 1428.6412 1428.5664 1428.4445 1428.3203]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [4][0/952]\tTime: 0.533 (0.533)\tData: 0.473 (0.473)\tLoss: 1.7666 (1.7666)\n",
      "Epoch: [4][200/952]\tTime: 0.081 (0.083)\tData: 0.000 (0.002)\tLoss: 1.0264 (1.6065)\n",
      "Epoch: [4][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.4996 (1.5766)\n",
      "Epoch: [4][600/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 2.2633 (1.5679)\n",
      "Epoch: [4][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 2.2533 (1.5414)\n",
      "###### Epoch [4] ###### \n",
      "Time: 77.203 s\n",
      "Clustering loss: 1428.320 \n",
      "ConvNet loss: 1.538\n",
      "NMI against previous assignment: 0.280\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.542 (0.542)\n",
      "200 / 952\tTime: 0.017 (0.020)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2640.7644 1492.3861 1433.7793 1415.2573 1409.1788 1406.5498 1403.9396\n",
      " 1401.9727 1400.2697 1399.1871 1398.6157 1398.2842 1397.7936 1397.3402\n",
      " 1397.0344 1396.6456 1395.9601 1395.6133 1395.4436 1395.3264]\n",
      "k-means time: 10 s\n",
      "Assign pseudo labels\n",
      "Epoch: [5][0/952]\tTime: 0.540 (0.540)\tData: 0.495 (0.495)\tLoss: 1.7663 (1.7663)\n",
      "Epoch: [5][200/952]\tTime: 0.081 (0.083)\tData: 0.000 (0.003)\tLoss: 1.7280 (1.6261)\n",
      "Epoch: [5][400/952]\tTime: 0.082 (0.082)\tData: 0.000 (0.001)\tLoss: 1.8877 (1.5636)\n",
      "Epoch: [5][600/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 1.5323 (1.5289)\n",
      "Epoch: [5][800/952]\tTime: 0.078 (0.081)\tData: 0.000 (0.001)\tLoss: 2.2536 (1.5091)\n",
      "###### Epoch [5] ###### \n",
      "Time: 77.130 s\n",
      "Clustering loss: 1395.326 \n",
      "ConvNet loss: 1.498\n",
      "NMI against previous assignment: 0.399\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.553 (0.553)\n",
      "200 / 952\tTime: 0.017 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.017 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2773.1877 1511.7048 1470.6133 1460.5941 1455.4476 1451.352  1447.5759\n",
      " 1445.7305 1444.2892 1443.4558 1442.737  1441.9065 1441.3931 1441.1858\n",
      " 1440.5988 1439.5247 1437.951  1437.1271 1436.8433 1436.7313]\n",
      "k-means time: 10 s\n",
      "Assign pseudo labels\n",
      "Epoch: [6][0/952]\tTime: 0.525 (0.525)\tData: 0.472 (0.472)\tLoss: 1.8006 (1.8006)\n",
      "Epoch: [6][200/952]\tTime: 0.082 (0.083)\tData: 0.000 (0.002)\tLoss: 1.3398 (1.6264)\n",
      "Epoch: [6][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.4163 (1.6131)\n",
      "Epoch: [6][600/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.1354 (1.5998)\n",
      "Epoch: [6][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 1.2365 (1.5941)\n",
      "###### Epoch [6] ###### \n",
      "Time: 77.082 s\n",
      "Clustering loss: 1436.731 \n",
      "ConvNet loss: 1.595\n",
      "NMI against previous assignment: 0.445\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.511 (0.511)\n",
      "200 / 952\tTime: 0.018 (0.020)\n",
      "400 / 952\tTime: 0.019 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2628.9014 1535.6493 1504.6389 1491.1143 1482.4746 1475.2458 1470.7017\n",
      " 1467.3379 1465.6759 1464.5999 1464.1285 1463.7964 1463.4847 1463.2146\n",
      " 1463.0328 1462.9579 1462.9158 1462.8724 1462.8258 1462.7643]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [7][0/952]\tTime: 0.550 (0.550)\tData: 0.501 (0.501)\tLoss: 1.7811 (1.7811)\n",
      "Epoch: [7][200/952]\tTime: 0.082 (0.083)\tData: 0.000 (0.003)\tLoss: 0.9400 (1.5504)\n",
      "Epoch: [7][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.9327 (1.5533)\n",
      "Epoch: [7][600/952]\tTime: 0.079 (0.082)\tData: 0.000 (0.001)\tLoss: 2.2736 (1.5610)\n",
      "Epoch: [7][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 1.5756 (1.5608)\n",
      "###### Epoch [7] ###### \n",
      "Time: 77.243 s\n",
      "Clustering loss: 1462.764 \n",
      "ConvNet loss: 1.561\n",
      "NMI against previous assignment: 0.376\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.580 (0.580)\n",
      "200 / 952\tTime: 0.017 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2961.4324 1703.0841 1658.9373 1640.3804 1630.9036 1625.3628 1618.9995\n",
      " 1611.6768 1605.6003 1599.2456 1592.8762 1586.4113 1582.0532 1580.3911\n",
      " 1579.3679 1578.8016 1578.4054 1578.0636 1577.83   1577.7015]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [8][0/952]\tTime: 0.549 (0.549)\tData: 0.496 (0.496)\tLoss: 1.7988 (1.7988)\n",
      "Epoch: [8][200/952]\tTime: 0.081 (0.084)\tData: 0.000 (0.003)\tLoss: 0.6967 (1.4896)\n",
      "Epoch: [8][400/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 0.6552 (1.4678)\n",
      "Epoch: [8][600/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 1.4877 (1.4617)\n",
      "Epoch: [8][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 1.2855 (1.4632)\n",
      "###### Epoch [8] ###### \n",
      "Time: 77.262 s\n",
      "Clustering loss: 1577.702 \n",
      "ConvNet loss: 1.446\n",
      "NMI against previous assignment: 0.405\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.555 (0.555)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2787.4197 1654.4243 1634.1361 1627.7731 1624.3042 1622.0352 1620.2166\n",
      " 1618.7086 1617.6528 1616.7644 1615.8629 1614.9727 1613.7976 1612.3855\n",
      " 1610.476  1607.5432 1603.576  1598.2799 1592.3278 1588.283 ]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [9][0/952]\tTime: 0.549 (0.549)\tData: 0.484 (0.484)\tLoss: 1.7360 (1.7360)\n",
      "Epoch: [9][200/952]\tTime: 0.081 (0.083)\tData: 0.000 (0.003)\tLoss: 1.7931 (1.4574)\n",
      "Epoch: [9][400/952]\tTime: 0.082 (0.082)\tData: 0.000 (0.001)\tLoss: 1.7951 (1.4361)\n",
      "Epoch: [9][600/952]\tTime: 0.079 (0.082)\tData: 0.000 (0.001)\tLoss: 0.7352 (1.4243)\n",
      "Epoch: [9][800/952]\tTime: 0.081 (0.081)\tData: 0.000 (0.001)\tLoss: 1.0021 (1.4213)\n",
      "###### Epoch [9] ###### \n",
      "Time: 77.276 s\n",
      "Clustering loss: 1588.283 \n",
      "ConvNet loss: 1.415\n",
      "NMI against previous assignment: 0.273\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.571 (0.571)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [3037.7798 1741.7089 1707.2616 1694.6045 1688.7155 1683.2153 1679.8671\n",
      " 1678.2888 1677.1143 1676.3727 1675.9165 1675.4943 1675.0192 1674.4778\n",
      " 1674.1473 1673.8684 1673.6425 1673.3683 1673.1537 1673.0186]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [10][0/952]\tTime: 0.552 (0.552)\tData: 0.508 (0.508)\tLoss: 1.8228 (1.8228)\n",
      "Epoch: [10][200/952]\tTime: 0.081 (0.084)\tData: 0.000 (0.003)\tLoss: 0.6831 (1.6399)\n",
      "Epoch: [10][400/952]\tTime: 0.082 (0.082)\tData: 0.000 (0.001)\tLoss: 1.5210 (1.5539)\n",
      "Epoch: [10][600/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.5240 (1.5294)\n",
      "Epoch: [10][800/952]\tTime: 0.079 (0.081)\tData: 0.000 (0.001)\tLoss: 0.9776 (1.5228)\n",
      "###### Epoch [10] ###### \n",
      "Time: 77.239 s\n",
      "Clustering loss: 1673.019 \n",
      "ConvNet loss: 1.517\n",
      "NMI against previous assignment: 0.226\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.571 (0.571)\n",
      "200 / 952\tTime: 0.017 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2971.0857 1712.6395 1680.4713 1669.7839 1665.772  1663.3765 1661.0865\n",
      " 1658.711  1655.4075 1654.1902 1653.4491 1652.9119 1652.3278 1651.6722\n",
      " 1650.9783 1650.3683 1649.8951 1649.4614 1649.1642 1649.0116]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [11][0/952]\tTime: 0.523 (0.523)\tData: 0.469 (0.469)\tLoss: 1.7813 (1.7813)\n",
      "Epoch: [11][200/952]\tTime: 0.081 (0.083)\tData: 0.000 (0.002)\tLoss: 0.9272 (1.5248)\n",
      "Epoch: [11][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.5779 (1.4783)\n",
      "Epoch: [11][600/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.4598 (1.4906)\n",
      "Epoch: [11][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 1.6691 (1.4956)\n",
      "###### Epoch [11] ###### \n",
      "Time: 77.182 s\n",
      "Clustering loss: 1649.012 \n",
      "ConvNet loss: 1.479\n",
      "NMI against previous assignment: 0.413\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.570 (0.570)\n",
      "200 / 952\tTime: 0.017 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [3073.736  1765.3903 1737.4165 1726.5371 1720.9025 1716.4742 1712.6708\n",
      " 1709.9731 1707.5708 1705.5922 1704.1824 1703.305  1702.8875 1702.5574\n",
      " 1702.2605 1702.0029 1701.7786 1701.66   1701.5907 1701.5258]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [12][0/952]\tTime: 0.545 (0.545)\tData: 0.478 (0.478)\tLoss: 1.7843 (1.7843)\n",
      "Epoch: [12][200/952]\tTime: 0.081 (0.083)\tData: 0.000 (0.002)\tLoss: 1.4823 (1.4513)\n",
      "Epoch: [12][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.3518 (1.4512)\n",
      "Epoch: [12][600/952]\tTime: 0.079 (0.082)\tData: 0.000 (0.001)\tLoss: 2.9165 (1.4528)\n",
      "Epoch: [12][800/952]\tTime: 0.079 (0.081)\tData: 0.000 (0.001)\tLoss: 0.6090 (1.4405)\n",
      "###### Epoch [12] ###### \n",
      "Time: 77.146 s\n",
      "Clustering loss: 1701.526 \n",
      "ConvNet loss: 1.444\n",
      "NMI against previous assignment: 0.346\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.541 (0.541)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2937.2205 1737.5759 1705.5721 1693.2677 1686.7666 1681.9458 1679.8878\n",
      " 1678.9949 1678.2253 1677.2134 1676.1846 1675.1261 1674.4386 1674.0176\n",
      " 1673.6128 1673.3375 1673.1051 1672.8446 1672.5162 1672.3185]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [13][0/952]\tTime: 0.559 (0.559)\tData: 0.506 (0.506)\tLoss: 1.8517 (1.8517)\n",
      "Epoch: [13][200/952]\tTime: 0.081 (0.084)\tData: 0.000 (0.003)\tLoss: 1.4333 (1.5177)\n",
      "Epoch: [13][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.2993 (1.4526)\n",
      "Epoch: [13][600/952]\tTime: 0.082 (0.082)\tData: 0.000 (0.001)\tLoss: 1.8560 (1.4323)\n",
      "Epoch: [13][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 1.0185 (1.4136)\n",
      "###### Epoch [13] ###### \n",
      "Time: 77.327 s\n",
      "Clustering loss: 1672.318 \n",
      "ConvNet loss: 1.410\n",
      "NMI against previous assignment: 0.270\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.576 (0.576)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [3005.3179 1758.7322 1737.2018 1723.201  1711.8457 1705.2258 1701.9231\n",
      " 1699.1659 1696.5061 1693.5189 1690.3619 1687.8156 1685.3011 1682.9958\n",
      " 1681.5969 1680.78   1679.9161 1679.2501 1678.68   1678.3419]\n",
      "k-means time: 12 s\n",
      "Assign pseudo labels\n",
      "Epoch: [14][0/952]\tTime: 0.584 (0.584)\tData: 0.540 (0.540)\tLoss: 1.7992 (1.7992)\n",
      "Epoch: [14][200/952]\tTime: 0.082 (0.084)\tData: 0.000 (0.003)\tLoss: 1.2388 (1.3806)\n",
      "Epoch: [14][400/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 1.9032 (1.3552)\n",
      "Epoch: [14][600/952]\tTime: 0.079 (0.082)\tData: 0.000 (0.001)\tLoss: 1.2104 (1.3404)\n",
      "Epoch: [14][800/952]\tTime: 0.078 (0.081)\tData: 0.000 (0.001)\tLoss: 0.6940 (1.3120)\n",
      "###### Epoch [14] ###### \n",
      "Time: 77.306 s\n",
      "Clustering loss: 1678.342 \n",
      "ConvNet loss: 1.301\n",
      "NMI against previous assignment: 0.309\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.544 (0.544)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.019 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [2994.6504 1763.8722 1743.8922 1735.2294 1729.7229 1725.6313 1722.3239\n",
      " 1719.5219 1716.9872 1715.5361 1714.5754 1713.781  1712.9812 1712.2415\n",
      " 1711.0958 1709.737  1708.8735 1707.9445 1707.0457 1706.3281]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [15][0/952]\tTime: 0.545 (0.545)\tData: 0.490 (0.490)\tLoss: 1.8256 (1.8256)\n",
      "Epoch: [15][200/952]\tTime: 0.086 (0.084)\tData: 0.000 (0.003)\tLoss: 1.4516 (1.4106)\n",
      "Epoch: [15][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 0.6857 (1.3883)\n",
      "Epoch: [15][600/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 1.0118 (1.3882)\n",
      "Epoch: [15][800/952]\tTime: 0.081 (0.081)\tData: 0.000 (0.001)\tLoss: 1.4722 (1.3634)\n",
      "###### Epoch [15] ###### \n",
      "Time: 77.330 s\n",
      "Clustering loss: 1706.328 \n",
      "ConvNet loss: 1.360\n",
      "NMI against previous assignment: 0.403\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.549 (0.549)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.019 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [3096.977  1788.7064 1760.9624 1738.3184 1720.2759 1705.3729 1698.5719\n",
      " 1692.9503 1688.4192 1685.8654 1684.1881 1683.1425 1682.0887 1681.0629\n",
      " 1680.4402 1680.1172 1679.8235 1679.4435 1679.1624 1678.9695]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [16][0/952]\tTime: 0.550 (0.550)\tData: 0.484 (0.484)\tLoss: 1.8122 (1.8122)\n",
      "Epoch: [16][200/952]\tTime: 0.081 (0.083)\tData: 0.000 (0.003)\tLoss: 1.5074 (1.4463)\n",
      "Epoch: [16][400/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 1.1582 (1.3859)\n",
      "Epoch: [16][600/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 0.6255 (1.3582)\n",
      "Epoch: [16][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 1.4905 (1.3371)\n",
      "###### Epoch [16] ###### \n",
      "Time: 77.266 s\n",
      "Clustering loss: 1678.969 \n",
      "ConvNet loss: 1.331\n",
      "NMI against previous assignment: 0.386\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.527 (0.527)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [3086.6558 1745.0417 1696.8357 1669.9023 1656.1365 1649.4366 1645.7831\n",
      " 1642.9902 1640.9298 1639.0404 1637.8633 1637.219  1636.361  1635.5553\n",
      " 1634.9938 1634.7437 1634.596  1634.4995 1634.3802 1634.1978]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [17][0/952]\tTime: 0.570 (0.570)\tData: 0.522 (0.522)\tLoss: 1.7843 (1.7843)\n",
      "Epoch: [17][200/952]\tTime: 0.081 (0.084)\tData: 0.000 (0.003)\tLoss: 1.0251 (1.4579)\n",
      "Epoch: [17][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.4373 (1.3988)\n",
      "Epoch: [17][600/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 1.4632 (1.3808)\n",
      "Epoch: [17][800/952]\tTime: 0.079 (0.081)\tData: 0.000 (0.001)\tLoss: 2.1787 (1.3512)\n",
      "###### Epoch [17] ###### \n",
      "Time: 77.213 s\n",
      "Clustering loss: 1634.198 \n",
      "ConvNet loss: 1.334\n",
      "NMI against previous assignment: 0.311\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.551 (0.551)\n",
      "200 / 952\tTime: 0.018 (0.021)\n",
      "400 / 952\tTime: 0.018 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [3078.3684 1780.7638 1755.3047 1744.0522 1738.0509 1733.276  1729.1852\n",
      " 1726.1943 1723.6218 1721.9631 1721.2987 1720.6632 1719.8495 1718.6394\n",
      " 1717.2275 1715.9026 1714.6853 1713.4965 1711.5327 1707.3866]\n",
      "k-means time: 10 s\n",
      "Assign pseudo labels\n",
      "Epoch: [18][0/952]\tTime: 0.502 (0.502)\tData: 0.441 (0.441)\tLoss: 1.6441 (1.6441)\n",
      "Epoch: [18][200/952]\tTime: 0.081 (0.083)\tData: 0.000 (0.002)\tLoss: 1.2223 (1.4352)\n",
      "Epoch: [18][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 1.0029 (1.3801)\n",
      "Epoch: [18][600/952]\tTime: 0.080 (0.082)\tData: 0.000 (0.001)\tLoss: 0.6793 (1.3342)\n",
      "Epoch: [18][800/952]\tTime: 0.080 (0.081)\tData: 0.000 (0.001)\tLoss: 1.3308 (1.3212)\n",
      "###### Epoch [18] ###### \n",
      "Time: 77.095 s\n",
      "Clustering loss: 1707.387 \n",
      "ConvNet loss: 1.310\n",
      "NMI against previous assignment: 0.335\n",
      "####################### \n",
      "\n",
      "Compute features\n",
      "0 / 952\tTime: 0.526 (0.526)\n",
      "200 / 952\tTime: 0.018 (0.020)\n",
      "400 / 952\tTime: 0.019 (0.019)\n",
      "600 / 952\tTime: 0.018 (0.019)\n",
      "800 / 952\tTime: 0.018 (0.019)\n",
      "Cluster the features\n",
      "k-means loss evolution: [3122.4392 1797.5715 1773.6914 1761.006  1751.9851 1745.9448 1739.2266\n",
      " 1729.1719 1718.7986 1707.9176 1703.2379 1701.9598 1701.1913 1700.5955\n",
      " 1700.0892 1699.4653 1698.8804 1698.2714 1697.3538 1696.7062]\n",
      "k-means time: 11 s\n",
      "Assign pseudo labels\n",
      "Epoch: [19][0/952]\tTime: 0.566 (0.566)\tData: 0.513 (0.513)\tLoss: 1.8520 (1.8520)\n",
      "Epoch: [19][200/952]\tTime: 0.082 (0.084)\tData: 0.000 (0.003)\tLoss: 0.5754 (1.2288)\n",
      "Epoch: [19][400/952]\tTime: 0.081 (0.082)\tData: 0.000 (0.001)\tLoss: 2.8177 (1.2148)\n",
      "Epoch: [19][600/952]\tTime: 0.079 (0.082)\tData: 0.000 (0.001)\tLoss: 1.0045 (1.2000)\n",
      "Epoch: [19][800/952]\tTime: 0.079 (0.081)\tData: 0.000 (0.001)\tLoss: 0.9779 (1.1921)\n",
      "###### Epoch [19] ###### \n",
      "Time: 77.362 s\n",
      "Clustering loss: 1696.706 \n",
      "ConvNet loss: 1.185\n",
      "NMI against previous assignment: 0.430\n",
      "####################### \n",
      "\n",
      "Clustering Losses: [1764.6022, 1451.6779, 1345.4794, 1186.6477, 1428.3203, 1395.3264, 1436.7313, 1462.7643, 1577.7015, 1588.283, 1673.0186, 1649.0116, 1701.5258, 1672.3185, 1678.3419, 1706.3281, 1678.9695, 1634.1978, 1707.3866, 1696.7062]\n",
      "Losses [2.5460224683169557, 1.6801736669129683, 1.6810097845286882, 1.5522207030478645, 1.5377004182889682, 1.4975386950023033, 1.5951965743002772, 1.5608501051153456, 1.446431006704058, 1.4148147458664508, 1.5173291409341227, 1.479497223779434, 1.443910490815379, 1.409538593738019, 1.3006273798581933, 1.3603775649636733, 1.3314913117459841, 1.3340588870043515, 1.309999556163279, 1.1851813116369128]\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py {DIR} --exp {EXP} --arch {ARCH} --lr {LR} --wd {WD}\\\n",
    "  --k {K} --sobel --verbose --workers {WORKERS} --epochs {EPOCHS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering_Losses = [1764.6022, 1451.6779, 1345.4794, 1186.6477, 1428.3203, 1395.3264, 1436.7313, 1462.7643, 1577.7015, 1588.283, 1673.0186, 1649.0116, 1701.5258, 1672.3185, 1678.3419, 1706.3281, 1678.9695, 1634.1978, 1707.3866, 1696.7062]\n",
    "Losses = [2.5460224683169557, 1.6801736669129683, 1.6810097845286882, 1.5522207030478645, 1.5377004182889682, 1.4975386950023033, 1.5951965743002772, 1.5608501051153456, 1.446431006704058, 1.4148147458664508, 1.5173291409341227, 1.479497223779434, 1.443910490815379, 1.409538593738019, 1.3006273798581933, 1.3603775649636733, 1.3314913117459841, 1.3340588870043515, 1.309999556163279, 1.1851813116369128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(EPOCHS), Losses)\n",
    "plt.title('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log\n",
    "\n",
    "### 15/02/21 -Ira - Following Error:\n",
    "Esnure you are using this version due to a object depreciation that means the clustering does not run on the newer version\n",
    "\n",
    "Fix: ```pip3 unintall faiss-gpu```\n",
    "```pip3 install faiss-gpu==1.6.1```\n",
    "\n",
    "### 16/02/21 -Ira - Following Error:\n",
    "Reduce PCA to 10 as a trial due to following error:\n",
    "```failed: PCA matrix cannot output 256 dimensions from 4096```\n",
    "\n",
    "Reduce number of clusters to 6:\n",
    "```Error: 'nx >= k' failed: need at least as many training points as clusters```\n",
    "\n",
    "Also reduce final sequential layer in the model from ```4096``` to ```2048``` to help with the dimentionailty reduction due to the low resoltuion of the input images from sentinel to overcome: \n",
    "\n",
    "### 19/02/21 -Ira - Following Error:\n",
    "```\n",
    "RuntimeError: Error in virtual void faiss::Clustering::train(faiss::Clustering::idx_t, const float*, faiss::Index&) at Clustering.cpp:90: Error: 'finite (x_in[i])' failed: input contains NaN's or Inf's\n",
    "```\n",
    "\n",
    "Niave solution: reduce the learning rate from ```0.05``` to ```0.005```. This 100% gets stuck in a local minima, however at least it works!\n",
    "\n",
    "\n",
    "It also takes forever and as the performance doesn't get better over time, due to being in this minima- reduce epochs from ```200``` to ```20```. \n",
    "\n",
    "Action points, change this learning rate- improve PCA and K-means.\n",
    "\n",
    "### 22/02/21 -Ira:\n",
    "\n",
    "Generated more data points restrictions on dimentionailty: Increase PCA to ```64``` as a trial due to following error. Model runs somewhat better now. Next step: be more selective on training images to esnure model is given a balanced dataset.\n",
    "\n",
    "Generated smaller dataset tiles as to include less different types in each image.\n",
    "\n",
    "### 23/02/21 -Ira:\n",
    "\n",
    "Increased the learning rate to ```0.05``` however this just overfit the model, reduced to ```0.01```.\n",
    "\n",
    "Created inference notebook to see how the model classifies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
