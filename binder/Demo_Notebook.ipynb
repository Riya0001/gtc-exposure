{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTC EXPOSURE DEMO PRODUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipyleaflet import Map, basemaps, LocalTileLayer, ImageOverlay, ScaleControl, LayersControl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "# Settlement Segmentation - Per Pixel Random Forrest Classifier\n",
    "Locates where the informal setttlement are given an image from Sentinel-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "# Change Detection - Image Ratio Demo\n",
    "This detects change between satellite images taken at subsequent times over the same location.\n",
    "\n",
    "The methods are calibrated on [Sentinel-2](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/overview) pre-post disaster imagery from the Caribbean and [Copernicus Emergency Mapping Service (EMS)](https://emergency.copernicus.eu/mapping/map-of-activations-rapid#zoom=3&lat=29.18235&lon=-70.57787&layers=BT00) ground truth damage assessment data. Section 4 allows you to evaluate predicted damages against reported damages for locations covered by EMS. The models were built using the [Descartes Labs](https://www.descarteslabs.com/) platform. If you wish to re-train the models or have more flexibility in your parameters, plots or methods, please visit the notebooks for each method at [thresholding.ipynb](./thresholding.ipynb) and [unet_classifier.ipynb](./unet_classifier.ipynb).\n",
    "#### Contents\n",
    "- 1 - [Visualise Subsequent Imagery](#visualiseImagery)\n",
    "- 2 - [Detect Change - Thresholding Method](#thresholding)\n",
    "- 3 - [Detect Change - Trained Classifier Method](#classifier)\n",
    "- 4 - [Evaluate Methods Against Ground Data](#evaluate)\n",
    "____________\n",
    "### Initialisation - Choose Location\n",
    "Firstly we need to choose a location for which to detect change. You may either choose one of the locations with pre-assigned variables from the list displayed when running the first cell, or you can choose a new location by selecting 'New Location' which will then prompt you to provide variables of your own when running the second cell. Pre-set locations are the following:\n",
    "- Training Set: Roseau, Dominica (pre-post hurricane Maria); Abricots, Haiti (pre-post hurricane Matthew)\n",
    "- Test Set: Jeremie, Haiti (pre-post hurricane Matthew); Port Salut, Haiti (pre-post hurricane Matthew)\n",
    "- Informal Settlements: Bidonville Killick Stenio Vincent, Port-au-Prince, Haiti (2018 to 2019); Parry Town, Ocho Rios, Jamaica (2018 to 2019)\n",
    "- High Resolution: Hidalgo County, Texas, USA (2016 to 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import change_detection.ratio_method.demoFunctions as dfn # Import functions from demoFunction.py\n",
    "location = dfn.chooseLocation() # Generate pre-defined location list\n",
    "location # Display location dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables for chosen location\n",
    "variables = dfn.assignVariables(location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submits input variables for new location (if not new location - no action)\n",
    "variables = dfn.submitNewLocation(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "<a id='visualiseImagery'></a>\n",
    "### 1 - Visualise Imagery\n",
    "We'll start by displaying before and after images for the chosen location. Two pointers here:\n",
    "- You'll need to click the magic markers below the map to scale the imagery band colours properly. You can also untick the 'After' box to toggle between pre and post disaster.\n",
    "- If you have defined a new location and no imagery appears for your location, try increasing the cloud fraction, but check this does not lead to overly cloudy images which may affect detection performance. Alternatively try changing or widening the requested dates, it is not uncommon to span several months for a good image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map with before and after images for specified location\n",
    "dfn.beforeAfterImages(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id='thresholding'></a>\n",
    "### 2 - Detect Change - Ratio Thresholding\n",
    "Next, let's take the logarithmic ratio of images for selected bands and display detected change superimposed on the image for time 2. Beneath the plot is a slider allowing you to vary the thresholds within which we are detecting change. If damage assessment data is available for the location this will be overlayed for a qualitative comparison.\n",
    "\n",
    "> The optimal threshold interval for detecting building change has been determined as 0.01-0.1. However, due to differences in lighting between repeat images this may need adjsuted according to location. As the ratio is logarithmic, if the second image is considerably darker than the first, the appropriate thresholding may even be negative.\n",
    "\n",
    "Detection interval equation for RGB (red, green and blue bands) where, for example, r1 denotes pixel value for red band at time 1:  $ threshold < \\log\\left(\\frac{r2}{r1} \\times \\frac{b2}{b1} \\times \\frac{g2}{g1}\\right) < cap  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect change through thresholding for location\n",
    "plotVars = dfn.thresholding(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may observe 2 main limitations with this method.\n",
    "- Lack of small scale change detections due to 10x10m resolution of Sentinel Imagery. Try re-running the notebook selecting the high resolution location to see what is possible where 1x1m resolution is available.\n",
    "- Sensitivity of thresholding to image lighting and changes in areas other than buildings, due to effect on ratio values. If threshold is unadjusted or mask is not applied to ocean this leads to false detections. To mitigate this limitation we trained a [classifier](#classifier) in the next section to recognise the evidence of damage buildings within the image ratio rather than relying on simple thresholding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "<a id='classifier'></a>\n",
    "### 3 - Detect Change - Ratio Classifier\n",
    "To avoid the drawbacks of thresholding we trained a Convolutional Neural Network (CNN) with a [U-Net](https://arxiv.org/abs/1505.04597) architecture to identify building change from the pixel ratios between before/after Sentinel-2 imagery. This model evaluates change per 'image tile' of which there will be many within your area of interest. Therefore, first let's draw a polygon over the desired area. Then, each corresponding tile will individually be fed in to the model for assessing change detection. Bare in mind the larger the area the longer it will take to run the model for that area.\n",
    "> One could question the decision not to just increase tilesize. However not only does this method make the evaluation area more flexible, but also the model does not cater well for tile sizes larger than that for which it was trained due to the input layer structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3, testPoly = dfn.drawPolygon(variables) # Get map upon which to draw polygon for assessment\n",
    "m3 # Display map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect change for all tiles at least partly within polygon\n",
    "dfn.classifyDamage(testPoly, variables, m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "# Change Detection - Deep Learning Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import change_detection.deep_change_detection.change_detection_demo as dcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "# Exposure Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exposure_quantification.exposure_demo as exq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9025e99106af44d2b408cdcfd3e08fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[18.51097696266426, -72.29284267872913], controls=(ZoomControl(options=['position', 'zoom_in_text',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "center, zoom, rel_url_S2, rel_url_BU, rel_url_POP, bounds = exq.exposure_quantification()\n",
    "m = Map(basemap=basemaps.OpenStreetMap.Mapnik, center=center, zoom=zoom)\n",
    "m.add_control(ScaleControl(position='bottomleft'))\n",
    "m.add_layer(ImageOverlay(name='Sentinel-2 Composite', url=rel_url_S2, bounds=bounds))\n",
    "m.add_layer(ImageOverlay(name='GHSL Built-up Probability', url=rel_url_BU, bounds= bounds, opacity=0.7))\n",
    "m.add_layer(ImageOverlay(name='GHSL Population Density', url=rel_url_POP, bounds=bounds, opacity=0.5))\n",
    "m.add_control(LayersControl(position='topright'))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____________' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a05f68bed767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m____________\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Change Detection High Resolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '____________' is not defined"
     ]
    }
   ],
   "source": [
    "____________\n",
    "# Change Detection High Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
