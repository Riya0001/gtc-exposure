{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet_xBD_damage_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on:\n",
    "\n",
    "https://github.com/DIUx-xView/xView2_second_place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-de29c3d9e3de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxview_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXviewSingleDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedDataParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_syncbn_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'apex'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from albumentations.pytorch.functional import img_to_tensor\n",
    "from skimage.measure import label\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "from os import cpu_count\n",
    "\n",
    "import cv2\n",
    "from cv2 import fillPoly\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "from shapely.geometry import mapping\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import cv2\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "import models\n",
    "from augs import SafeRotate, Lighting\n",
    "\n",
    "from albumentations import Compose, RandomSizedCrop, HorizontalFlip, VerticalFlip, RGBShift, RandomBrightnessContrast, \\\n",
    "    RandomGamma, OneOf, RandomRotate90, Transpose, RandomCrop, HueSaturationValue, ImageCompression\n",
    "\n",
    "import losses\n",
    "from dataset.xview_dataset import XviewSingleDataset\n",
    "\n",
    "from apex.parallel import DistributedDataParallel, convert_syncbn_model\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tools.config import load_config\n",
    "from tools.utils import create_optimizer, AverageMeter\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "from losses import dice_round\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.distributed as dist\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from tools.xview_metric import XviewMetrics\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import cv2\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "import models\n",
    "from augs import Lighting, RandomSizedCropAroundBbox\n",
    "\n",
    "from albumentations import Compose, HorizontalFlip, VerticalFlip, RGBShift, RandomBrightnessContrast, \\\n",
    "    RandomGamma, RandomRotate90, Transpose\n",
    "\n",
    "import losses\n",
    "from dataset.xview_dataset import XviewSingleDataset\n",
    "\n",
    "from apex.parallel import DistributedDataParallel, convert_syncbn_model\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tools.config import load_config\n",
    "from tools.utils import create_optimizer, AverageMeter\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "from losses import dice_round\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.distributed as dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to import and normalise the data\n",
    "\n",
    "\n",
    "class XviewSingleDataset(Dataset):\n",
    "    def __init__(self, data_path, mode, fold=0, folds_csv='folds.csv', equibatch=False, transforms=None, normalize=None,\n",
    "                 multiplier=1):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.mode = mode\n",
    "\n",
    "        self.names = sorted(os.listdir(os.path.join(self.data_path, \"images\")))\n",
    "        df = pd.read_csv(folds_csv, dtype={'id': object})\n",
    "        self.df = df\n",
    "        self.normalize = normalize\n",
    "        self.fold = fold\n",
    "        self.equibatch = equibatch\n",
    "        if self.mode == \"train\":\n",
    "            ids = df[df['fold'] != fold]['id'].tolist()\n",
    "            nondamage = df[(df['fold'] != fold) & (df['nondamage'] == True)]['id'].tolist()\n",
    "            minor = df[(df['fold'] != fold) & (df['minor'] == True)]['id'].tolist()\n",
    "            major = df[(df['fold'] != fold) & (df['major'] == True)]['id'].tolist()\n",
    "            destroyed = df[(df['fold'] != fold) & (df['destroyed'] == True)]['id'].tolist()\n",
    "            empty = df[(df['fold'] != fold) & (df['empty'] == True)]['id'].tolist()\n",
    "\n",
    "            self.group_names = {\n",
    "                \"nondamage1\": nondamage,\n",
    "                \"nondamage\": nondamage,\n",
    "                \"minor\": minor,\n",
    "                \"major\": major,\n",
    "                \"destroyed\": destroyed,\n",
    "                \"empty\": empty,\n",
    "            }\n",
    "            self.group_ids = list(self.group_names.keys())\n",
    "            if not self.equibatch:\n",
    "                ids.extend(minor)\n",
    "                ids.extend(major)\n",
    "                ids.extend(destroyed)\n",
    "        else:\n",
    "            ids = list(set(df[df['fold'] == fold]['id'].tolist()))\n",
    "        self.transforms = transforms\n",
    "        self.names = ids\n",
    "\n",
    "        if mode == \"train\":\n",
    "            self.names = self.names * multiplier\n",
    "        self.cache = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.mode == 'train' and self.equibatch:\n",
    "            group_id = self.group_ids[idx % len(self.group_ids)]\n",
    "            name = random.choice(self.group_names[group_id])\n",
    "        else:\n",
    "            group_id = \"unknown\"\n",
    "            name = self.names[idx]\n",
    "        pre_img_path = os.path.join(self.data_path, \"images\", name + \"_pre_disaster.png\")\n",
    "        post_img_path = os.path.join(self.data_path, \"images\", name + \"_post_disaster.png\")\n",
    "        image_pre = cv2.imread(pre_img_path, cv2.IMREAD_COLOR)[:, :, ::-1]\n",
    "        image_post = cv2.imread(post_img_path, cv2.IMREAD_COLOR)[:, :, ::-1]\n",
    "        mask_pre = cv2.imread(os.path.join(self.data_path, \"masks\", name + \"_pre_disaster.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "        mask_post = cv2.imread(os.path.join(self.data_path, \"masks\", name + \"_post_disaster.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        rectangles = self.cache.get(self.names[idx], [])\n",
    "        if not rectangles:\n",
    "            self.add_boxes(label(mask_post == 2).astype(np.uint8), rectangles)\n",
    "        if rectangles:\n",
    "            self.cache[self.names[idx]] = rectangles\n",
    "\n",
    "        mask = np.stack([mask_pre, mask_post, mask_post], axis=-1)\n",
    "        sample = self.transforms(image=image_pre, image1=image_post, mask=mask, img_name=name, rectangles=rectangles)\n",
    "        image = np.concatenate([sample['image'], sample['image1']], axis=-1)\n",
    "        sample['img_name'] = name\n",
    "        sample['group_id'] = group_id\n",
    "        mask = np.zeros((5, *sample[\"mask\"].shape[:2]))\n",
    "        for i in range(1, 5):\n",
    "            mask[i - 1, sample[\"mask\"][:, :, 1] == i] = 1\n",
    "        mask[4] = sample[\"mask\"][:, :, 0] / 255\n",
    "        del sample[\"image1\"]\n",
    "        sample['original_mask'] = torch.from_numpy(np.ascontiguousarray(sample[\"mask\"][:, :, 1]))\n",
    "        sample['mask'] = torch.from_numpy(np.ascontiguousarray(mask)).float()\n",
    "        sample['image'] = img_to_tensor(np.ascontiguousarray(image), self.normalize)\n",
    "        return sample\n",
    "\n",
    "    def add_boxes(self, labels, rectangles):\n",
    "        max_label = np.max(labels)\n",
    "        for i in range(1, max_label + 1):\n",
    "            obj_mask = np.zeros_like(labels)\n",
    "            obj_mask[labels == i] = 255\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(obj_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for cnt in contours:\n",
    "                points = cv2.boundingRect(cnt)\n",
    "                rectangles.append(points)\n",
    "\n",
    "\n",
    "\n",
    "class XviewSingleDatasetTest(Dataset):\n",
    "    def __init__(self, data_path, transforms=None, normalize=None):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.names = list(set([os.path.splitext(f)[0].replace(\"test_post_\", \"\").replace(\"test_pre_\", \"\") for f in\n",
    "                               sorted(os.listdir(os.path.join(self.data_path, \"images\")))]))\n",
    "        self.normalize = normalize\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "        pre_img_path = os.path.join(self.data_path, \"images\", \"test_pre_\" + name + \".png\")\n",
    "        post_img_path = os.path.join(self.data_path, \"images\", \"test_post_\" + name + \".png\")\n",
    "\n",
    "        image_pre = cv2.imread(pre_img_path, cv2.IMREAD_COLOR)[:, :, ::-1]\n",
    "        image_post = cv2.imread(post_img_path, cv2.IMREAD_COLOR)[:, :, ::-1]\n",
    "        image = np.concatenate([image_pre, image_post], axis=-1)\n",
    "        sample = {}\n",
    "        sample['img_name'] = name\n",
    "        sample['image'] = img_to_tensor(np.ascontiguousarray(image), self.normalize)\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input INPUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/jovyan/.local/share/jupyter/runtime/kernel-e29f9431-eb41-4cee-b92f-fb6658306756.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3425: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#This script will generate pixel masks from json files.\n",
    "\n",
    "\n",
    "def generate_localization_polygon(json_path, out_dir):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "    h = annotations[\"metadata\"][\"height\"]\n",
    "    w = annotations[\"metadata\"][\"width\"]\n",
    "    mask_img = np.zeros((h, w), np.uint8)\n",
    "    out_filename = os.path.splitext(os.path.basename(json_path))[0] + \".png\"\n",
    "    for feat in annotations['features']['xy']:\n",
    "        feat_shape = wkt.loads(feat['wkt'])\n",
    "        coords = list(mapping(feat_shape)['coordinates'][0])\n",
    "        fillPoly(mask_img, [np.array(coords, np.int32)], (255))\n",
    "    cv2.imwrite(os.path.join(out_dir, out_filename), mask_img)\n",
    "\n",
    "\n",
    "def generate_damage_polygon(json_path, out_dir):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    h = annotations[\"metadata\"][\"height\"]\n",
    "    w = annotations[\"metadata\"][\"width\"]\n",
    "    mask_img = np.zeros((h, w), np.uint8)\n",
    "\n",
    "    damage_dict = {\n",
    "        \"no-damage\": 1,\n",
    "        \"minor-damage\": 2,\n",
    "        \"major-damage\": 3,\n",
    "        \"destroyed\": 4,\n",
    "        \"un-classified\": 255\n",
    "    }\n",
    "    out_filename = os.path.splitext(os.path.basename(json_path))[0] + \".png\"\n",
    "    for feat in annotations['features']['xy']:\n",
    "        feat_shape = wkt.loads(feat['wkt'])\n",
    "        coords = list(mapping(feat_shape)['coordinates'][0])\n",
    "        fillPoly(mask_img, [np.array(coords, np.int32)], damage_dict[feat['properties']['subtype']])\n",
    "    cv2.imwrite(os.path.join(out_dir, out_filename), mask_img)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input',\n",
    "                        default=\"/home/selim/datasets/xview/train/\",\n",
    "                        help='Path to parent dataset directory \"xBD\"')\n",
    "    args = parser.parse_args()\n",
    "    out_dir = os.path.join(args.input, \"masks\")\n",
    "    in_dir = os.path.join(args.input, \"labels\")\n",
    "    pre_images = [os.path.join(in_dir, f) for f in os.listdir(in_dir) if '_pre_' in f]\n",
    "    post_images = [os.path.join(in_dir, f) for f in os.listdir(in_dir) if '_post_' in f]\n",
    "\n",
    "    pool = Pool(cpu_count())\n",
    "    with tqdm(total=len(pre_images)) as pbar:\n",
    "        for i, v in enumerate(pool.imap_unordered(partial(generate_localization_polygon, out_dir=out_dir), pre_images)):\n",
    "            pbar.update()\n",
    "    with tqdm(total=len(post_images)) as pbar:\n",
    "        for i, v in enumerate(pool.imap_unordered(partial(generate_damage_polygon, out_dir=out_dir), post_images)):\n",
    "            pbar.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localisation Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: PyTorch Xview Pipeline [-h] [--config CONFIG_FILE] [--workers WORKERS]\n",
      "                              [--gpu GPU] [--output-dir OUTPUT_DIR]\n",
      "                              [--resume RESUME] [--fold FOLD]\n",
      "                              [--prefix PREFIX] [--data-dir DATA_DIR]\n",
      "                              [--folds-csv FOLDS_CSV] [--logdir LOGDIR]\n",
      "                              [--zero-score] [--from-zero] [--distributed]\n",
      "                              [--freeze-epochs FREEZE_EPOCHS]\n",
      "                              [--local_rank LOCAL_RANK]\n",
      "                              [--opt-level OPT_LEVEL]\n",
      "                              [--predictions PREDICTIONS]\n",
      "                              [--test_every TEST_EVERY]\n",
      "PyTorch Xview Pipeline: error: unrecognized arguments: -f /home/jovyan/.local/share/jupyter/runtime/kernel-e29f9431-eb41-4cee-b92f-fb6658306756.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#Used to train binary segmentation models. By default O0 opt level (FP32) is used for Apex due to unstable loss during training.\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def create_train_transforms(conf):\n",
    "    height = conf['crop_height']\n",
    "    width = conf['crop_width']\n",
    "    return Compose([\n",
    "        SafeRotate(45, p=0.4, border_mode=cv2.BORDER_CONSTANT),\n",
    "        OneOf([\n",
    "            RandomSizedCrop(min_max_height=(int(height * 0.7), int(height * 1.3)), w2h_ratio=1., height=height,\n",
    "                            width=width, p=0.8),\n",
    "            RandomCrop(height=height, width=width, p=0.2)], p=1),\n",
    "        HorizontalFlip(),\n",
    "        VerticalFlip(),\n",
    "        RandomRotate90(),\n",
    "        Transpose(),\n",
    "        ImageCompression(p=0.1),\n",
    "        Lighting(alphastd=0.3),\n",
    "        RandomBrightnessContrast(p=0.4),\n",
    "        RandomGamma(p=0.4),\n",
    "        OneOf([RGBShift(), HueSaturationValue()], p=0.2)\n",
    "    ], additional_targets={'image1': 'image'}\n",
    "    )\n",
    "\n",
    "\n",
    "def create_val_transforms(conf):\n",
    "    return Compose([\n",
    "    ], additional_targets={'image1': 'image'})\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\"PyTorch Xview Pipeline\")\n",
    "    arg = parser.add_argument\n",
    "    arg('--config', metavar='CONFIG_FILE', help='path to configuration file')\n",
    "    arg('--workers', type=int, default=8, help='number of cpu threads to use')\n",
    "    arg('--gpu', type=str, default='0', help='List of GPUs for parallel training, e.g. 0,1,2,3')\n",
    "    arg('--output-dir', type=str, default='weights/')\n",
    "    arg('--resume', type=str, default='')\n",
    "    arg('--fold', type=int, default=0)\n",
    "    arg('--prefix', type=str, default='localization_')\n",
    "    arg('--data-dir', type=str, default=\"/home/selim/datasets/xview/train\")\n",
    "    arg('--folds-csv', type=str, default='folds.csv')\n",
    "    arg('--logdir', type=str, default='logs')\n",
    "    arg('--zero-score', action='store_true', default=False)\n",
    "    arg('--from-zero', action='store_true', default=False)\n",
    "    arg('--distributed', action='store_true', default=False)\n",
    "    arg('--freeze-epochs', type=int, default=1)\n",
    "    arg(\"--local_rank\", default=0, type=int)\n",
    "    arg(\"--opt-level\", default='O0', type=str)\n",
    "    arg(\"--predictions\", default=\"../oof_preds\", type=str)\n",
    "    arg(\"--test_every\", type=int, default=1)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.distributed:\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "    else:\n",
    "        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    conf = load_config(args.config)\n",
    "    model = models.__dict__[conf['network']](seg_classes=conf['num_classes'], backbone_arch=conf['encoder'])\n",
    "\n",
    "    model = model.cuda()\n",
    "    if args.distributed:\n",
    "        model = convert_syncbn_model(model)\n",
    "    mask_loss_function = losses.__dict__[conf[\"mask_loss\"][\"type\"]](**conf[\"mask_loss\"][\"params\"]).cuda()\n",
    "    loss_functions = {\"mask_loss\": mask_loss_function}\n",
    "    optimizer, scheduler = create_optimizer(conf['optimizer'], model)\n",
    "\n",
    "    dice_best = 0\n",
    "    start_epoch = 0\n",
    "    batch_size = conf['optimizer']['batch_size']\n",
    "\n",
    "    data_train = XviewSingleDataset(mode=\"train\",\n",
    "                                    fold=args.fold,\n",
    "                                    data_path=args.data_dir,\n",
    "                                    folds_csv=args.folds_csv,\n",
    "                                    transforms=create_train_transforms(conf['input']),\n",
    "                                    multiplier=conf[\"data_multiplier\"],\n",
    "                                    normalize=conf[\"input\"].get(\"normalize\", None))\n",
    "    data_val = XviewSingleDataset(mode=\"val\",\n",
    "                                  fold=args.fold,\n",
    "                                  data_path=args.data_dir,\n",
    "                                  folds_csv=args.folds_csv,\n",
    "                                  transforms=create_val_transforms(conf['input']),\n",
    "                                  normalize=conf[\"input\"].get(\"normalize\", None)\n",
    "                                  )\n",
    "    train_sampler = None\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(data_train)\n",
    "\n",
    "    train_data_loader = DataLoader(data_train, batch_size=batch_size, num_workers=args.workers,\n",
    "                                   shuffle=train_sampler is None, sampler=train_sampler, pin_memory=False,\n",
    "                                   drop_last=True)\n",
    "    val_batch_size = 1\n",
    "    val_data_loader = DataLoader(data_val, batch_size=val_batch_size, num_workers=args.workers, shuffle=False,\n",
    "                                 pin_memory=False)\n",
    "\n",
    "    os.makedirs(args.logdir, exist_ok=True)\n",
    "    summary_writer = SummaryWriter(args.logdir + '/' + args.prefix + conf['encoder'])\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "            state_dict = checkpoint['state_dict']\n",
    "            if conf['optimizer'].get('zero_decoder', False):\n",
    "                for key in state_dict.copy().keys():\n",
    "                    if key.startswith(\"module.final\"):\n",
    "                        del state_dict[key]\n",
    "            state_dict = {k[7:]: w for k, w in state_dict.items()}\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "            if not args.from_zero:\n",
    "                start_epoch = checkpoint['epoch']\n",
    "                if not args.zero_score:\n",
    "                    dice_best = checkpoint.get('dice_best', 0)\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "    if args.from_zero:\n",
    "        start_epoch = 0\n",
    "    current_epoch = start_epoch\n",
    "\n",
    "    if conf['fp16']:\n",
    "        model, optimizer = amp.initialize(model, optimizer,\n",
    "                                          opt_level=args.opt_level,\n",
    "                                          loss_scale='dynamic')\n",
    "\n",
    "    snapshot_name = \"{}{}_{}_{}\".format(args.prefix, conf['network'], conf['encoder'], args.fold)\n",
    "\n",
    "    if args.distributed:\n",
    "        model = DistributedDataParallel(model, delay_allreduce=True)\n",
    "    else:\n",
    "        model = DataParallel(model).cuda()\n",
    "    for epoch in range(start_epoch, conf['optimizer']['schedule']['epochs']):\n",
    "        if train_sampler:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        if epoch < args.freeze_epochs:\n",
    "            print(\"Freezing encoder!!!\")\n",
    "            model.module.encoder_stages.eval()\n",
    "            for p in model.module.encoder_stages.parameters():\n",
    "                p.requires_grad = False\n",
    "        else:\n",
    "            print(\"Unfreezing encoder!!!\")\n",
    "            model.module.encoder_stages.train()\n",
    "            for p in model.module.encoder_stages.parameters():\n",
    "                p.requires_grad = True\n",
    "        train_epoch(current_epoch, loss_functions, model, optimizer, scheduler, train_data_loader, summary_writer, conf,\n",
    "                    args.local_rank)\n",
    "\n",
    "        model = model.eval()\n",
    "        if args.local_rank == 0:\n",
    "            torch.save({\n",
    "                'epoch': current_epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'dice_best': dice_best,\n",
    "            }, args.output_dir + '/' + snapshot_name + \"_last\")\n",
    "            if epoch % args.test_every == 0:\n",
    "                preds_dir = os.path.join(args.predictions, snapshot_name)\n",
    "                dice_best = evaluate_val(args, val_data_loader, dice_best, model,\n",
    "                                                     snapshot_name=snapshot_name,\n",
    "                                                     current_epoch=current_epoch,\n",
    "                                                     optimizer=optimizer, summary_writer=summary_writer,\n",
    "                                                     predictions_dir=preds_dir)\n",
    "        current_epoch += 1\n",
    "\n",
    "\n",
    "def evaluate_val(args, data_val, dice_best, model, snapshot_name, current_epoch, optimizer, summary_writer,\n",
    "                 predictions_dir):\n",
    "    print(\"Test phase\")\n",
    "    model = model.eval()\n",
    "    dice = validate(model, data_loader=data_val, predictions_dir=predictions_dir)\n",
    "    if args.local_rank == 0:\n",
    "        summary_writer.add_scalar('val/dice', float(dice), global_step=current_epoch)\n",
    "        if dice > dice_best:\n",
    "            if args.output_dir is not None:\n",
    "                torch.save({\n",
    "                    'epoch': current_epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'dice_best': dice,\n",
    "\n",
    "                }, args.output_dir + snapshot_name + \"_best_dice\")\n",
    "            dice_best = dice\n",
    "        torch.save({\n",
    "            'epoch': current_epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'dice_best': dice_best,\n",
    "        }, args.output_dir + snapshot_name + \"_last\")\n",
    "        print(\"dice: {}, dice_best: {}\".format(dice, dice_best))\n",
    "    return dice_best\n",
    "\n",
    "\n",
    "def validate(net, data_loader, predictions_dir):\n",
    "    os.makedirs(predictions_dir, exist_ok=True)\n",
    "    preds_dir = predictions_dir + \"/predictions\"\n",
    "    os.makedirs(preds_dir, exist_ok=True)\n",
    "    dices = []\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(data_loader):\n",
    "            imgs = sample[\"image\"].cuda().float()[:, :3, :, :]\n",
    "            mask = sample[\"mask\"].cuda().float()\n",
    "\n",
    "            output = net(imgs)\n",
    "            binary_pred = torch.sigmoid(output)\n",
    "\n",
    "            for i in range(output.shape[0]):\n",
    "                d = dice_round(binary_pred, mask[:, 4:, ...], t=0.5).item()\n",
    "                dices.append(d)\n",
    "                cv2.imwrite(os.path.join(preds_dir, \"test_localization_\" + sample[\"img_name\"][i] + \"_prediction.png\"),\n",
    "                            (binary_pred[i, 0].cpu().numpy() > 0.5) * 1)\n",
    "    return np.mean(dices)\n",
    "\n",
    "\n",
    "def train_epoch(current_epoch, loss_functions, model, optimizer, scheduler, train_data_loader, summary_writer, conf,\n",
    "                local_rank):\n",
    "    losses = AverageMeter()\n",
    "    dices = AverageMeter()\n",
    "    iterator = tqdm(train_data_loader)\n",
    "    model.train()\n",
    "    if conf[\"optimizer\"][\"schedule\"][\"mode\"] == \"epoch\":\n",
    "        scheduler.step(current_epoch)\n",
    "    for i, sample in enumerate(iterator):\n",
    "        imgs = sample[\"image\"].cuda()[:, :3, :, :]\n",
    "        masks = sample[\"mask\"].cuda().float()\n",
    "        out_mask = model(imgs)\n",
    "        mask_band = 4\n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(out_mask)\n",
    "            d = dice_round(pred, masks[:, mask_band:, ...], t=0.5).item()\n",
    "        dices.update(d, imgs.size(0))\n",
    "\n",
    "        mask_loss = loss_functions[\"mask_loss\"](out_mask, masks[:, mask_band:, ...].contiguous())\n",
    "        loss = mask_loss\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "        iterator.set_description(\n",
    "            \"epoch: {}; lr {:.7f}; Loss ({loss.avg:.4f}); dice ({dice.avg:.4f}); \".format(\n",
    "                current_epoch, scheduler.get_lr()[-1], loss=losses, dice=dices))\n",
    "        optimizer.zero_grad()\n",
    "        if conf['fp16']:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), 1)\n",
    "        optimizer.step()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        if conf[\"optimizer\"][\"schedule\"][\"mode\"] in (\"step\", \"poly\"):\n",
    "            scheduler.step(i + current_epoch * len(train_data_loader))\n",
    "\n",
    "    if local_rank == 0:\n",
    "        for idx, param_group in enumerate(optimizer.param_groups):\n",
    "            lr = param_group['lr']\n",
    "            summary_writer.add_scalar('group{}/lr'.format(idx), float(lr), global_step=current_epoch)\n",
    "        summary_writer.add_scalar('train/loss', float(losses.avg), global_step=current_epoch)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def create_train_transforms(conf):\n",
    "    height = conf['crop_height']\n",
    "    width = conf['crop_width']\n",
    "    return Compose([\n",
    "        RandomSizedCropAroundBbox(min_max_height=(int(height * 0.8), int(height * 1.2)), w2h_ratio=1., height=height,\n",
    "                               width=width, p=1),\n",
    "        HorizontalFlip(),\n",
    "        VerticalFlip(),\n",
    "        RandomRotate90(),\n",
    "        Transpose(),\n",
    "        Lighting(alphastd=0.3),\n",
    "        RandomBrightnessContrast(p=0.2),\n",
    "        RandomGamma(p=0.2),\n",
    "        RGBShift(p=0.2)\n",
    "    ], additional_targets={'image1': 'image'}\n",
    "    )\n",
    "\n",
    "\n",
    "def create_val_transforms(conf):\n",
    "    return Compose([\n",
    "    ], additional_targets={'image1': 'image'})\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\"PyTorch Xview Pipeline\")\n",
    "    arg = parser.add_argument\n",
    "    arg('--config', metavar='CONFIG_FILE', help='path to configuration file')\n",
    "    arg('--workers', type=int, default=6, help='number of cpu threads to use')\n",
    "    arg('--gpu', type=str, default='0', help='List of GPUs for parallel training, e.g. 0,1,2,3')\n",
    "    arg('--output-dir', type=str, default='weights/')\n",
    "    arg('--resume', type=str, default='')\n",
    "    arg('--fold', type=int, default=0)\n",
    "    arg('--prefix', type=str, default='damage_')\n",
    "    arg('--data-dir', type=str, default=\"/home/selim/datasets/xview/train\")\n",
    "    arg('--folds-csv', type=str, default='folds.csv')\n",
    "    arg('--logdir', type=str, default='logs')\n",
    "    arg('--zero-score', action='store_true', default=False)\n",
    "    arg('--from-zero', action='store_true', default=False)\n",
    "    arg('--distributed', action='store_true', default=False)\n",
    "    arg('--freeze-epochs', type=int, default=1)\n",
    "    arg(\"--local_rank\", default=0, type=int)\n",
    "    arg(\"--opt-level\", default='O1', type=str)\n",
    "    arg(\"--predictions\", default=\"../oof_preds\", type=str)\n",
    "    arg(\"--test_every\", type=int, default=1)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.distributed:\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "    else:\n",
    "        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    conf = load_config(args.config)\n",
    "    model = models.__dict__[conf['network']](seg_classes=conf['num_classes'], backbone_arch=conf['encoder'])\n",
    "\n",
    "    model = model.cuda()\n",
    "    if args.distributed:\n",
    "        model = convert_syncbn_model(model)\n",
    "    damage_loss_function = losses.__dict__[conf[\"damage_loss\"][\"type\"]](**conf[\"damage_loss\"][\"params\"]).cuda()\n",
    "    mask_loss_function = losses.__dict__[conf[\"mask_loss\"][\"type\"]](**conf[\"mask_loss\"][\"params\"]).cuda()\n",
    "    loss_functions = {\"damage_loss\": damage_loss_function, \"mask_loss\": mask_loss_function}\n",
    "    optimizer, scheduler = create_optimizer(conf['optimizer'], model)\n",
    "\n",
    "    dice_best = 0\n",
    "    xview_best = 0\n",
    "    start_epoch = 0\n",
    "    batch_size = conf['optimizer']['batch_size']\n",
    "\n",
    "    data_train = XviewSingleDataset(mode=\"train\",\n",
    "                                    fold=args.fold,\n",
    "                                    data_path=args.data_dir,\n",
    "                                    folds_csv=args.folds_csv,\n",
    "                                    transforms=create_train_transforms(conf['input']),\n",
    "                                    multiplier=conf[\"data_multiplier\"],\n",
    "                                    normalize=conf[\"input\"].get(\"normalize\", None))\n",
    "    data_val = XviewSingleDataset(mode=\"val\",\n",
    "                                  fold=args.fold,\n",
    "                                  data_path=args.data_dir,\n",
    "                                  folds_csv=args.folds_csv,\n",
    "                                  transforms=create_val_transforms(conf['input']),\n",
    "                                  normalize=conf[\"input\"].get(\"normalize\", None)\n",
    "                                  )\n",
    "    train_sampler = None\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(data_train)\n",
    "\n",
    "    train_data_loader = DataLoader(data_train, batch_size=batch_size, num_workers=args.workers,\n",
    "                                   shuffle=train_sampler is None, sampler=train_sampler, pin_memory=False,\n",
    "                                   drop_last=True)\n",
    "    val_batch_size = 1\n",
    "    val_data_loader = DataLoader(data_val, batch_size=val_batch_size, num_workers=args.workers, shuffle=False,\n",
    "                                 pin_memory=False)\n",
    "\n",
    "    os.makedirs(args.logdir, exist_ok=True)\n",
    "    summary_writer = SummaryWriter(args.logdir + '/' + args.prefix + conf['encoder'])\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "            state_dict = checkpoint['state_dict']\n",
    "            if conf['optimizer'].get('zero_decoder', False):\n",
    "                for key in state_dict.copy().keys():\n",
    "                    if key.startswith(\"module.final\"):\n",
    "                        del state_dict[key]\n",
    "            state_dict = {k[7:]: w for k, w in state_dict.items()}\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "            if not args.from_zero:\n",
    "                start_epoch = checkpoint['epoch']\n",
    "                if not args.zero_score:\n",
    "                    dice_best = checkpoint.get('dice_best', 0)\n",
    "                    xview_best = checkpoint.get('xview_best', 0)\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "    if args.from_zero:\n",
    "        start_epoch = 0\n",
    "    current_epoch = start_epoch\n",
    "\n",
    "    if conf['fp16']:\n",
    "        model, optimizer = amp.initialize(model, optimizer,\n",
    "                                          opt_level=args.opt_level,\n",
    "                                          loss_scale='dynamic')\n",
    "\n",
    "    snapshot_name = \"{}{}_{}_{}\".format(args.prefix, conf['network'], conf['encoder'], args.fold)\n",
    "\n",
    "    if args.distributed:\n",
    "        model = DistributedDataParallel(model, delay_allreduce=True)\n",
    "    else:\n",
    "        model = DataParallel(model).cuda()\n",
    "    for epoch in range(start_epoch, conf['optimizer']['schedule']['epochs']):\n",
    "        if epoch < args.freeze_epochs:\n",
    "            print(\"Freezing encoder!!!\")\n",
    "            if hasattr(model.module, 'encoder_stages1'):\n",
    "                model.module.encoder_stages1.eval()\n",
    "                model.module.encoder_stages2.eval()\n",
    "                for p in model.module.encoder_stages1.parameters():\n",
    "                    p.requires_grad = False\n",
    "                for p in model.module.encoder_stages2.parameters():\n",
    "                    p.requires_grad = False\n",
    "            else:\n",
    "                model.module.encoder_stages.eval()\n",
    "                for p in model.module.encoder_stages.parameters():\n",
    "                    p.requires_grad = False\n",
    "        else:\n",
    "            if hasattr(model.module, 'encoder_stages1'):\n",
    "                print(\"Unfreezing encoder!!!\")\n",
    "                model.module.encoder_stages1.train()\n",
    "                model.module.encoder_stages2.train()\n",
    "                for p in model.module.encoder_stages1.parameters():\n",
    "                    p.requires_grad = True\n",
    "                for p in model.module.encoder_stages2.parameters():\n",
    "                    p.requires_grad = True\n",
    "            else:\n",
    "                model.module.encoder_stages.train()\n",
    "                for p in model.module.encoder_stages.parameters():\n",
    "                    p.requires_grad = True\n",
    "        train_epoch(current_epoch, loss_functions, model, optimizer, scheduler, train_data_loader, summary_writer, conf,\n",
    "                    args.local_rank)\n",
    "\n",
    "        model = model.eval()\n",
    "        if args.local_rank == 0:\n",
    "            torch.save({\n",
    "                'epoch': current_epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'dice_best': dice_best,\n",
    "                'xview_best': xview_best,\n",
    "            }, args.output_dir + '/' + snapshot_name + \"_last\")\n",
    "            if epoch % args.test_every == 0:\n",
    "                preds_dir = os.path.join(args.predictions, snapshot_name)\n",
    "                dice_best, xview_best = evaluate_val(args, val_data_loader, xview_best, dice_best, model,\n",
    "                                                     snapshot_name=snapshot_name,\n",
    "                                                     current_epoch=current_epoch,\n",
    "                                                     optimizer=optimizer, summary_writer=summary_writer,\n",
    "                                                     predictions_dir=preds_dir)\n",
    "        current_epoch += 1\n",
    "\n",
    "\n",
    "def evaluate_val(args, data_val, xview_best, dice_best, model, snapshot_name, current_epoch, optimizer, summary_writer,\n",
    "                 predictions_dir):\n",
    "    print(\"Test phase\")\n",
    "    model = model.eval()\n",
    "    dice, xview_score = validate(model, data_loader=data_val, predictions_dir=predictions_dir)\n",
    "    if args.local_rank == 0:\n",
    "        summary_writer.add_scalar('val/dice', float(dice), global_step=current_epoch)\n",
    "        summary_writer.add_scalar('val/xview_score', float(xview_score), global_step=current_epoch)\n",
    "        if dice > dice_best:\n",
    "            if args.output_dir is not None:\n",
    "                torch.save({\n",
    "                    'epoch': current_epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'dice_best': dice,\n",
    "                    'xview_best': xview_score,\n",
    "\n",
    "                }, args.output_dir + snapshot_name + \"_best_dice\")\n",
    "            dice_best = dice\n",
    "        if xview_score > xview_best:\n",
    "            if args.output_dir is not None:\n",
    "                torch.save({\n",
    "                    'epoch': current_epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'dice_best': dice,\n",
    "                    'xview_best': xview_score,\n",
    "                }, args.output_dir + snapshot_name + \"_best_xview\")\n",
    "            xview_best = xview_score\n",
    "        torch.save({\n",
    "            'epoch': current_epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'dice_best': dice_best,\n",
    "            'xview_best': xview_best,\n",
    "        }, args.output_dir + snapshot_name + \"_last\")\n",
    "        print(\"dice: {}, dice_best: {}\".format(dice, dice_best))\n",
    "        print(\"xview: {}, xview_best: {}\".format(xview_score, xview_best))\n",
    "    return dice_best, xview_best\n",
    "\n",
    "\n",
    "def validate(net, data_loader, predictions_dir):\n",
    "    os.makedirs(predictions_dir, exist_ok=True)\n",
    "    preds_dir = predictions_dir + \"/predictions\"\n",
    "    os.makedirs(preds_dir, exist_ok=True)\n",
    "    targs_dir = predictions_dir + \"/targets\"\n",
    "    os.makedirs(targs_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(data_loader):\n",
    "            imgs = sample[\"image\"].cuda().float()\n",
    "            mask = sample[\"mask\"].cuda().float()\n",
    "            original_mask = sample[\"original_mask\"].cuda().long().cpu().numpy()\n",
    "\n",
    "            output = net(imgs)\n",
    "            binary_pred = torch.sigmoid(output[:, 4:, ...])\n",
    "\n",
    "            damage_preds = torch.sigmoid(output[:, :4, ...]).cpu().numpy()\n",
    "            for i in range(output.shape[0]):\n",
    "                damage_pred = damage_preds[i]\n",
    "                first = np.zeros((1, 1024, 1024))\n",
    "                first[:, :, :] = 0.1\n",
    "                damage_pred = np.concatenate([first, damage_pred], axis=0)\n",
    "                cv2.imwrite(os.path.join(preds_dir,\n",
    "                                         \"test_localization_\" + sample[\"img_name\"][i] + \"_prediction.png\"),\n",
    "                            (binary_pred[i, 0].cpu().numpy() > 0.3) * 1)\n",
    "                cv2.imwrite(os.path.join(preds_dir,\n",
    "                                         \"test_damage_\" + sample[\"img_name\"][i] + \"_prediction.png\"),\n",
    "                            np.argmax(damage_pred, axis=0))\n",
    "                cv2.imwrite(os.path.join(targs_dir,\n",
    "                                         \"test_localization_\" + sample[\"img_name\"][i] + \"_target.png\"),\n",
    "                            mask.cpu().numpy()[i, 4])\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(targs_dir, \"test_damage_\" + sample[\"img_name\"][i] + \"_target.png\"),\n",
    "                    original_mask[i])\n",
    "    d = XviewMetrics.compute_score(preds_dir, targs_dir, \"out.json\")\n",
    "    for k, v in d.items():\n",
    "        print(\"{}:{}\".format(k, v))\n",
    "    return d[\"localization_f1\"], d[\"score\"]\n",
    "\n",
    "\n",
    "def train_epoch(current_epoch, loss_functions, model, optimizer, scheduler, train_data_loader, summary_writer, conf,\n",
    "                local_rank):\n",
    "    losses = AverageMeter()\n",
    "    damage_f1 = AverageMeter()\n",
    "    localization_f1 = AverageMeter()\n",
    "    iterator = tqdm(train_data_loader)\n",
    "    model.train()\n",
    "    if conf[\"optimizer\"][\"schedule\"][\"mode\"] == \"epoch\":\n",
    "        scheduler.step(current_epoch)\n",
    "    for i, sample in enumerate(iterator):\n",
    "        imgs = sample[\"image\"].cuda()\n",
    "        masks = sample[\"mask\"].cuda().float()\n",
    "        out_mask = model(imgs)\n",
    "        mask_band = 4\n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(out_mask[:, :, ...])\n",
    "            d = dice_round(pred[:, mask_band:, ...], masks[:, mask_band:, ...], t=0.5).item()\n",
    "            loc_f1 = 0\n",
    "            for i in range(4):\n",
    "                loc_f1 += 1/(dice_round(pred[:, i:i+1, ...], masks[:, i:i+1, ...], t=0.3).item() + 1e-3)\n",
    "            loc_f1 = 4/loc_f1\n",
    "        localization_f1.update(d, imgs.size(0))\n",
    "        damage_f1.update(loc_f1, imgs.size(0))\n",
    "\n",
    "        mask_loss = loss_functions[\"mask_loss\"](out_mask[:, mask_band:, ...].contiguous(),\n",
    "                                                masks[:, mask_band:, ...].contiguous())\n",
    "        damage_loss = loss_functions[\"damage_loss\"](out_mask[:, :mask_band, ...].contiguous(),\n",
    "                                                    masks[:, :mask_band, ...].contiguous())\n",
    "        loss = 0.7 * damage_loss + 0.3 * mask_loss\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "        iterator.set_description(\n",
    "            \"epoch: {}; lr {:.7f}; Loss ({loss.avg:.4f}); Localization F1 ({dice.avg:.4f}); Damage F1 ({damage.avg:.4f}); \".format(\n",
    "                current_epoch, scheduler.get_lr()[-1], loss=losses, dice=localization_f1, damage=damage_f1))\n",
    "        optimizer.zero_grad()\n",
    "        if conf['fp16']:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), 1)\n",
    "        optimizer.step()\n",
    "        torch.cuda.synchronize()\n",
    "        if conf[\"optimizer\"][\"schedule\"][\"mode\"] in (\"step\", \"poly\"):\n",
    "            scheduler.step(i + current_epoch * len(train_data_loader))\n",
    "\n",
    "    if local_rank == 0:\n",
    "        for idx, param_group in enumerate(optimizer.param_groups):\n",
    "            lr = param_group['lr']\n",
    "            summary_writer.add_scalar('group{}/lr'.format(idx), float(lr), global_step=current_epoch)\n",
    "        summary_writer.add_scalar('train/loss', float(losses.avg), global_step=current_epoch)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
