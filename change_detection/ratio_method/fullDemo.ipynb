{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Detection - Image Ratio Demo\n",
    "This notebook detects change between satellite images taken at subsequent times over the same location.\n",
    "\n",
    "The methods are calibrated on [Sentinel-2](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/overview) pre-post disaster imagery from the Caribbean and [Copernicus Emergency Mapping Service (EMS)](https://emergency.copernicus.eu/mapping/map-of-activations-rapid#zoom=3&lat=29.18235&lon=-70.57787&layers=BT00) ground truth damage assessment data. Section 4 allows you to evaluate predicted damages against reported damages for locations covered by EMS. The models were built using the [Descartes Labs](https://www.descarteslabs.com/) platform. If you wish to re-train the models or have more flexibility in your parameters, plots or methods, please visit the notebooks for each method at [thresholding.ipynb](./thresholding.ipynb) and [unet_classifier.ipynb](./unet_classifier.ipynb).\n",
    "### Contents\n",
    "- 1 - [Visualise Subsequent Imagery](#visualiseImagery)\n",
    "- 2 - [Detect Change - Thresholding Method](#thresholding)\n",
    "- 3 - [Detect Change - Trained Classifier Method](#classifier)\n",
    "- 4 - [Evaluate Methods Against Ground Data](#evaluate)\n",
    "____________\n",
    "## Initialisation - Choose Location\n",
    "Firstly we need to choose a location for which to detect change. You may either choose one of the locations with pre-assigned variables from the list displayed when running the first cell, or you can choose a new location by selecting 'New Location' which will then prompt you to provide variables of your own when running the second cell. Pre-set locations are the following:\n",
    "- Training Set: Roseau, Dominica (pre-post hurricane Maria); Abricots, Haiti (pre-post hurricane Matthew)\n",
    "- Test Set: Jeremie, Haiti (pre-post hurricane Matthew); Port Salut, Haiti (pre-post hurricane Matthew)\n",
    "- Informal Settlements: Bidonville Killick Stenio Vincent, Port-au-Prince, Haiti (2018 to 2019); Parry Town, Ocho Rios, Jamaica (2018 to 2019)\n",
    "- High Resolution: Hidalgo County, Texas, USA (2016 to 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b04bb925c6342bcac9f5415acde27a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Location:', options=(('train - Roseau, Dominica', 0), ('train - Abricots, Haiti', 1), ('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import demoFunctions as dfn # Import functions from demoFunction.py\n",
    "location = dfn.chooseLocation() # Generate pre-defined location list\n",
    "location # Display location dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457a67473dab40f1951ecfd8d8fd73df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=18.6486, description='Latitude (decimal):')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd23625821cc42d7aba279594bdf39aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=-74.3058, description='Longitude (decimal):')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ff5dee46d54cc6b3a06f28fc090392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=16, description='Map zoom:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb32739364244f288d154ad2f256536b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='2016-07-01', description='Image 1 start date:', placeholder='yyyy-mm-dd')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5158c8f8019445d809fe677624cf3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='2016-09-30', description='Image 1 end date:', placeholder='yyyy-mm-dd')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee75cb24e77243d0a0f074791d6ce056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='2016-10-06', description='Image 2 start date:', placeholder='yyyy-mm-dd')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a749ebe7285f4eb4ab89b572f6d32f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='2017-07-06', description='Image 2 end date:', placeholder='yyyy-mm-dd')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5318a945f9e443f9a9fb6388df1d61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='sentinel-2:L1C', description='Satellite:', placeholder='sentinel-2:L1C')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6da646769744aa2a39053e44d448809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.2, description='Cloud Fraction:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ff15b840a64377bc21e03f59ff274e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.01, description='Default threshold:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4fb3d452ff44ec80235b42e5428c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.1, description='Default Cap')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa098daf1741469db4a9f55abe2b895a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Imagery bands:', options=(('red', ['red']), ('green', ['green']), ('blue', ['blue']), ('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a7fbc8083a4a6792e7b8a56600f72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=10, description='Satellite resolution:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8b3012adc94a95b4fb905a1199495b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Path to mask if using one:', placeholder='mask.geojson')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign variables for chosen location\n",
    "variables = dfn.assignVariables(location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submits input variables for new location (if not new location - no action)\n",
    "variables = dfn.submitNewLocation(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "<a id='visualiseImagery'></a>\n",
    "## 1 - Visualise Imagery\n",
    "We'll start by displaying before and after images for the chosen location. Two pointers here:\n",
    "- You'll need to click the magic markers below the map to scale the imagery band colours properly. You can also untick the 'After' box to toggle between pre and post disaster.\n",
    "- If you have defined a new location and no imagery appears for your location, try increasing the cloud fraction, but check this does not lead to overly cloudy images which may affect detection performance. Alternatively try changing or widening the requested dates, it is not uncommon to span several months for a good image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e434ed64644d39a2644cc482b2b22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create map with before and after images for specified location\n",
    "dfn.beforeAfterImages(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id='thresholding'></a>\n",
    "## 2 - Detect Change - Ratio Thresholding\n",
    "Next, let's take the logarithmic ratio of images for selected bands and display detected change superimposed on the image for time 2. Beneath the plot is a slider allowing you to vary the thresholds within which we are detecting change. If damage assessment data is available for the location this will be overlayed for a qualitative comparison.\n",
    "\n",
    "> The optimal threshold interval for detecting building change has been determined as 0.01-0.1. However, due to differences in lighting between repeat images this may need adjsuted according to location. As the ratio is logarithmic, if the second image is considerably darker than the first, the appropriate thresholding may even be negative.\n",
    "\n",
    "Detection interval equation for RGB (red, green and blue bands) where, for example, r1 denotes pixel value for red band at time 1:  $ threshold < \\log\\left(\\frac{r2}{r1} \\times \\frac{b2}{b1} \\times \\frac{g2}{g1}\\right) < cap  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe78c3937c5464e9d0d7d9d980d970b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jup…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8a470420794ef2b707efc34d5bea5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(0.01, 0.1), description='Filter ratios', max=0.5, min=-0.5, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run box below to display updated detection result\n"
     ]
    }
   ],
   "source": [
    "# Function to detect change through thresholding for location\n",
    "plotVars = dfn.thresholding(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-plot detected change according to slider values\n",
    "dfn.plotChange(plotVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may observe 2 main limitations with this method.\n",
    "- Lack of small scale change detections due to 10x10m resolution of Sentinel Imagery. Try re-running the notebook selecting the high resolution location to see what is possible where 1x1m resolution is available.\n",
    "- Sensitivity of thresholding to image lighting and changes in areas other than buildings, due to effect on ratio values. If threshold is unadjusted or mask is not applied to ocean this leads to false detections. To mitigate this limitation we trained a [classifier](#classifier) in the next section to recognise the evidence of damage buildings within the image ratio rather than relying on simple thresholding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "<a id='classifier'></a>\n",
    "## 3 - Detect Change - Ratio Classifier\n",
    "To avoid the drawbacks of thresholding we trained a Convolutional Neural Network (CNN) with a [U-Net](https://arxiv.org/abs/1505.04597) architecture to identify building change from the pixel ratios between before/after Sentinel-2 imagery. This model evaluates change per 'image tile' of which there will be many within your area of interest. Therefore, first let's draw a polygon over the desired area. Then, each corresponding tile will individually be fed in to the model for assessing change detection. Bare in mind the larger the area the longer it will take to run the model for that area.\n",
    "> One could question the decision not to just increase tilesize. However not only does this method make the evaluation area more flexible, but also the model does not cater well for tile sizes larger than that for which it was trained due to the input layer structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16197cc6c714473eb1cbdd4f4d9c4ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m3, testPoly = dfn.drawPolygon(variables) # Get map upon which to draw polygon for assessment\n",
    "m3 # Display map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Latitude Rows:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Longitude Columns:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles requested: 15 . Approximately 120 seconds on 16GB RAM.\n",
      "\n",
      "Job ID: 0a44131df9ee8b14bf6611be17eaca6f5cc7bb1b9b54bc42\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  20%|██        | 1/5 [00:05<00:23,  5.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: ac5ed63804b81f6f21823cf8832153e0b4796865f82c26be\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  40%|████      | 2/5 [00:12<00:18,  6.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: aa054452ff8714e533258b33e3cf6c286f5ab770722b53fa\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  60%|██████    | 3/5 [00:18<00:11,  5.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 2ae85921e6dfcb9042c10d0fba234720d586e584371cc00c\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7e1ca1c3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  80%|████████  | 4/5 [00:23<00:05,  5.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 4c141fdee032d274a945ffbd7d81806a14fa9b0692004bdd\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7e0a9b7320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns: 100%|██████████| 5/5 [00:29<00:00,  5.90s/it]\u001b[A\n",
      "Latitude Rows:  33%|███▎      | 1/3 [00:29<00:59, 29.50s/it]\n",
      "Longitude Columns:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 38c9e4c7c9c2a07b8392f2eec7cbc694e4f99e2c82d6f37d\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7e0a912b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  20%|██        | 1/5 [00:05<00:23,  5.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: cee010ad203869ef3dff2c3ab27ef63d5e52b80cd6fa95c0\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7e08801440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  40%|████      | 2/5 [00:10<00:16,  5.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 24015393839550b293e59b1c53b97d38851ca479b1bafbcb\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7dfef1b560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  60%|██████    | 3/5 [00:16<00:11,  5.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 9f440a73fbd86d665a26657808fb73e42e1b71f2e7fc9d1c\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7dfe6e4290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  80%|████████  | 4/5 [00:22<00:05,  5.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: d3cce7ed9b3a4685e6ce90c5504d1b3f7535cdf7ccf82883\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7dfce0ca70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns: 100%|██████████| 5/5 [00:28<00:00,  5.73s/it]\u001b[A\n",
      "Latitude Rows:  67%|██████▋   | 2/3 [00:58<00:29, 29.25s/it]\n",
      "Longitude Columns:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: d57911889758e3f3eb8c93c02d44b40447251249f55edf8e\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7df751c8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  20%|██        | 1/5 [00:06<00:25,  6.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 7faecd71987f5365c78c391aa4f51e1de488e1155f09ea3d\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7dfe6e4440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  40%|████      | 2/5 [00:12<00:18,  6.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: e0ffab8390fac6770b11124d71a69bdd8ffa1811ee76d96c\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7df5c57cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  60%|██████    | 3/5 [00:17<00:12,  6.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: e047cc145f09677a4e1790f7f3789a7b75ffa52c5977f003\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7df4313a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  80%|████████  | 4/5 [00:23<00:06,  6.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: e729771a174eddeccc2cd5433f9f11d2212dfc943ec48323\n",
      "[######] | Steps: 5/5 | Stage: SUCCEEDED                                      WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7df2a40170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns: 100%|██████████| 5/5 [00:30<00:00,  6.17s/it]\u001b[A\n",
      "Latitude Rows: 100%|██████████| 3/3 [01:29<00:00, 29.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Detect change for all tiles at least partly within polygon\n",
    "dfn.classifyDamage(testPoly, variables, m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "<a id='evaluate'></a>\n",
    "## 4 - Evaluate Methods Against Ground Data\n",
    "We can now use Copernicus EMS post-disaster damage assessments to evaluate our models' performance at detecting building change. We will first plot a map evaluating thresholding accuracy, and then for classifier accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate against damages\n",
    "if not deployed:\n",
    "    # Load building damages and filter for within detection area\n",
    "    dmg = gpd.read_file(dmgJsons)\n",
    "    filtered = gpd.GeoDataFrame(crs={'init': 'epsg:4326'})\n",
    "\n",
    "    tilePoly = gpd.GeoSeries(Polygon.from_bounds(min(allCtx[0::4]),min(allCtx[1::4]),max(allCtx[2::4]),max(allCtx[3::4])), crs={'init':ctx.bounds_crs}).to_crs(epsg=4326).geometry[0]\n",
    "    for i in dmg.index: \n",
    "        if dmg.geometry[i].centroid.within(tilePoly):\n",
    "            filtered = filtered.append(dmg.loc[i])\n",
    "\n",
    "    print('Changed pixels:',len(allDet), '\\nDamaged buildings:',len(filtered))\n",
    "\n",
    "    # Initialise accuracy and recall vectors\n",
    "    acc, rec = np.zeros([max(filtered.index)+1,1]), np.zeros([max(allDet.index)+1,1]) # Initialise accuracy, recall arrays\n",
    "\n",
    "    # Loop through pixels to determine recall (if pixel corresponds to damaged building)\n",
    "    for i in tqdm(allDet.index):\n",
    "        # Loop through building to determine accuracy (damaged building has been detected)\n",
    "        for j in filtered.index:\n",
    "            if allDet.geometry[i].within(filtered.geometry[j]):\n",
    "                rec[i,0], acc[j,0] = True, True\n",
    "\n",
    "    # Calculate metrics from vector outputs\n",
    "    a = sum(acc)/len(filtered)\n",
    "    r = sum(rec)/len(allDet)\n",
    "    f1 = 2*(a*r)/(a+r)\n",
    "    print('Accuracy:',a[0],'\\nRecall:',r[0],'\\nF1 score:',f1[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "<a id='evaluate'></a>\n",
    "## 3 - Evaluate Detection Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mask into coordinate array\n",
    "# Get vector of pixels which have changed coordinates\n",
    "gtx, detection = wf.map.geocontext(), detections.mask(detections==0).mask(omitMask==1) if os.path.exists(maskPoly) else detections.mask(detections==0)\n",
    "change = detection.compute(geoctx=gtx)\n",
    "\n",
    "# Get latitude & longitude of each pixel in mask (whether true or false)\n",
    "bounds = change.geocontext['bounds']\n",
    "lats, longs = np.linspace(bounds[3],bounds[1],change.geocontext['arr_shape'][0]), np.linspace(bounds[0],bounds[2],change.geocontext['arr_shape'][1])\n",
    "\n",
    "# Create matrix of coordinates for pixels with change detected\n",
    "xm, ym = np.meshgrid(longs,lats)\n",
    "xc, yc = xm*(1-change.ndarray.mask[0]), ym*(1-change.ndarray.mask[0])\n",
    "\n",
    "# Get geodataframe for pixel points\n",
    "df = pd.DataFrame(columns=['Latitude', 'Longitude'])\n",
    "for i,j in tqdm(zip(np.nonzero(xc)[0], np.nonzero(xc)[1])):\n",
    "    df = df.append({'Latitude': yc[i][j],'Longitude': xc[i][j]}, ignore_index=True)\n",
    "    \n",
    "det = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in damage geojson from Copernicus EMS data\n",
    "try: \n",
    "    settlements = gpd.read_file(dmgAssess).to_crs({'init': 'epsg:4326'})\n",
    "    color_dict = {'Not Applicable':'green','Negligible to slight damage':'blue', 'Moderately Damaged':'yellow', 'Highly Damaged':'orange', 'Completely Destroyed':'red'}\n",
    "\n",
    "    # Filter settlements to be within specified damage grade and location polygon\n",
    "    damage = settlements[settlements.grading.isin(grades)]\n",
    "    damage = damage[damage.within(Polygon(change.geocontext['geometry']['coordinates'][0]))]\n",
    "\n",
    "    # Filter detections to area covered by damage inspection\n",
    "    try: det = det.loc[(det.geometry.x < max(damage.geometry.x)) & (det.geometry.x > min(damage.geometry.x)) & (det.geometry.y < max(damage.geometry.y)) & (det.geometry.y > min(damage.geometry.y))]\n",
    "    except: pass\n",
    "except: print(\"No damage file set for this area. All further steps are for assessing detection against a damage assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detected vs damaged in matplotlib\n",
    "# Plot damages\n",
    "try: # For assessments with damage points\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(damage.geometry.x,damage.geometry.y,color=[color_dict[i] for i in damage.grading],s=8,alpha=0.2,label='Building damage')\n",
    "except:  # For assessments with damage polygons\n",
    "    try: plt = damage.plot(figsize=(10,6),column='grading',alpha=1.,legend=True,cmap='RdYlGn')\n",
    "    except: print('As previously mentioned => No damage file to plot')\n",
    "        \n",
    "# Plot detections\n",
    "plt.scatter(det.geometry.x,det.geometry.y,s=1, label='Change detected')\n",
    "plt.legend()\n",
    "\n",
    "# Display detected and damages on interactive map\n",
    "# Initialise map\n",
    "m3 = wf.interactive.MapApp()\n",
    "m3.center, m3.zoom = (lat, lon), zoom\n",
    "\n",
    "# Plot background image and overlay damages\n",
    "after = globals()['mos_2'+str(visual)].visualize('After', map=m3)  \n",
    "geo_data = GeoData(geo_dataframe = damage, style={'color': 'red', 'radius':2, 'fillColor': 'red', 'opacity':0.2, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.2},\n",
    "                    hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                    point_style={'radius': 3, 'color': 'red', 'fillOpacity': 0.2, 'fillColor': 'red', 'weight': 3},\n",
    "                    name = 'Damages')\n",
    "m3.add_layer(geo_data)\n",
    "\n",
    "# Plot detections\n",
    "try: detection = detections.mask(detections==0).mask(omitMask==1).visualize('Detected Change', checkerboard=False, colormap='plasma', map=m3)\n",
    "except: detection = detections.mask(detections==0).visualize('Detected Change', checkerboard=False, colormap='plasma', map=m3)\n",
    "detection.opacity, after.opacity = 0.7, 0.6\n",
    "\n",
    "# Legend\n",
    "m3.add_control(LegendControl({\"Detected Change\":\"#FFFF00\", \"Recorded Damage\":\"#FF0000\"})) \n",
    "\n",
    "m3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id='quantify'></a>\n",
    "## 4 - Quantify Accuracy\n",
    "After qualitatively assessing the ratio method's performance in the previous section, we will now quantify the accuracy of the method for detecting building damage. \n",
    "\n",
    "For this we first define a building footprint around the recorded damage point location. We then determine the accuracy with which detected changed pixels correspond to these building footprints. The metrics are as follows:\n",
    "- Precision (proportion of damage detected): $P = \\frac{True Positives}{True Positives + False Positives}$\n",
    "- Recall (proportion of detections corresponding to damage): $R = \\frac{True Positives}{True Positives + False Negatives}$\n",
    "- F1 Score: $F1 = 2x\\frac{P*R}{P+R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polygons around point locations of damages\n",
    "if not os.path.exists(dmgFile) and damage.geometry[damage.index[0]].type is not 'Polygon': # Gets point assessment damages into geojson file\n",
    "    features = []\n",
    "    for i in tqdm(damage.index):\n",
    "        poly = Polygon([[damage.geometry.x[i], damage.geometry.y[i]], [damage.geometry.x[i]+area, damage.geometry.y[i]], [damage.geometry.x[i]+area, damage.geometry.y[i]+area], [damage.geometry.x[i], damage.geometry.y[i]+area], [damage.geometry.x[i], damage.geometry.y[i]]])\n",
    "        features.append(geojson.Feature(properties={\"Damage\": damage.grading[i]}, geometry=poly))\n",
    "\n",
    "    fc = geojson.FeatureCollection(features)\n",
    "    with open(dmgFile, 'w') as f: geojson.dump(fc, f)\n",
    "    \n",
    "elif not os.path.exists(dmgFile):  # Puts polygon assessments into geojson file\n",
    "    with open(dmgFile, 'w') as f: geojson.dump(damage, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load building damages\n",
    "dmg = gpd.read_file(dmgFile)\n",
    "print('Changed pixels:',len(det), '\\nDamaged buildings:',len(dmg))\n",
    "\n",
    "# Initialise accuracy and recall vectors\n",
    "acc, rec = np.zeros([max(dmg.index)+1,1]), np.zeros([max(det.index)+1,1]) # Initialise accuracy, recall arrays\n",
    "\n",
    "# Loop through pixels to determine recall (if pixel corresponds to damaged building)\n",
    "for i in tqdm(det.index):\n",
    "    # Loop through building to determine accuracy (damaged building has been detected)\n",
    "    for j in dmg.index:\n",
    "        if det.geometry[i].within(dmg.geometry[j]):\n",
    "            rec[i,0], acc[j,0] = True, True\n",
    "\n",
    "# Calculate metrics from vector outputs\n",
    "a = sum(acc)/len(dmg)\n",
    "r = sum(rec)/len(det)\n",
    "f1 = 2*(a*r)/(a+r)\n",
    "print('Precision:',a[0],'\\nRecall:',r[0],'\\nF1 score:',f1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot success of change detection in matplotlib and save figure\n",
    "# Damage detected true/false\n",
    "dmg['found'] = pd.Series(acc[:,0], index=dmg.index)\n",
    "plt = dmg.plot(figsize=(12,8), column='found',legend=True,cmap='RdYlGn',alpha = 0.7)\n",
    "\n",
    "# False detection points\n",
    "points = np.vstack([rec[i] for i in det.index])\n",
    "x1, y1 = np.array(det.geometry.x)*(1-points).transpose(), np.array(det.geometry.y)*(1-points).transpose()\n",
    "x1, y1 = x1[x1 != 0], y1[y1 != 0]\n",
    "plt.scatter(x1,y1,s=0.05,color='b', label='False detections')\n",
    "\n",
    "# Set titles and save\n",
    "plt.set_title('Threshold:'+str(threshold)+', Area:'+str(area)+', Kernel:'+str(kSize)+' - Acc:'+str(a[0])[:6]+', Re:'+str(r[0])[:6])\n",
    "plt.legend()\n",
    "plt.figure.savefig('results/'+location+'_t'+str(threshold)[2:]+'a'+str(area)[2:]+'g'+str(len(grades))+str(bands)+'.png')\n",
    "\n",
    "## Display on interactive map\n",
    "# Initialise map\n",
    "m4 = wf.interactive.MapApp()\n",
    "m4.center, m4.zoom = (lat, lon), zoom\n",
    "\n",
    "# Plot background imagery as image 2 using function from map 1\n",
    "getImage(1,visual,0.7,m4)\n",
    "\n",
    "# Add layers for building polygons whether red for not found, green for found\n",
    "not_found = GeoData(geo_dataframe = dmg.loc[dmg['found']==0], style={'color': 'red', 'radius':2, 'fillColor': 'red', 'opacity':0.7, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                    hover_style={'fillColor': 'red' , 'fillOpacity': 0.5},\n",
    "                    name = 'Damages')\n",
    "found = GeoData(geo_dataframe = dmg.loc[dmg['found']==1], style={'color': 'green', 'radius':2, 'fillColor': 'green', 'opacity':0.7, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                    hover_style={'fillColor': 'green' , 'fillOpacity': 0.5},\n",
    "                    name = 'Damages')\n",
    "m4.add_layer(not_found)\n",
    "m4.add_layer(found)\n",
    "\n",
    "# Plot pixels where change has been detected\n",
    "try: detection = detections.mask(detections==0).mask(omitMask==1).visualize('Detected Change', checkerboard=False, colormap='plasma', map=m4)\n",
    "except: detection = detections.mask(detections==0).visualize('Detected Change', checkerboard=False, colormap='plasma', map=m4)\n",
    "detection.opacity = 0.7\n",
    "\n",
    "# Legend\n",
    "m4.add_control(LegendControl({\"Detected Change\":\"#FFFF00\", \"Damage Identified\":\"#008000\", \"Damage Not Identified\":\"#FF0000\"})) \n",
    "\n",
    "m4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------- END ------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
