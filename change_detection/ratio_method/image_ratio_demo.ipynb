{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Detection - Image Ratio Demo\n",
    "This notebook detects change between satellite images taken at subsequent times over the same location.\n",
    "\n",
    "The methods are calibrated on [Sentinel-2](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/overview) pre-post disaster imagery from the Caribbean and [Copernicus Emergency Mapping Service (EMS)](https://emergency.copernicus.eu/mapping/map-of-activations-rapid#zoom=3&lat=29.18235&lon=-70.57787&layers=BT00) ground truth damage assessment data. Section 4 allows you to evaluate predicted damages against reported damages for locations covered by EMS. The models were built using the [Descartes Labs](https://www.descarteslabs.com/) platform. If you wish to re-train the models or have more flexibility in your parameters, plots or methods, please visit the notebooks for each method at [thresholding.ipynb](./thresholding.ipynb) and [unet_classifier.ipynb](./unet_classifier.ipynb).\n",
    "### Contents\n",
    "- 1 - [Visualise Subsequent Imagery](#visualiseImagery)\n",
    "- 2 - [Detect Change - Thresholding Method](#thresholding)\n",
    "- 3 - [Detect Change - Trained Classifier Method](#classifier)\n",
    "- 4 - [Evaluate Methods Against Ground Data](#evaluate)\n",
    "____________\n",
    "## Initialisation - Choose Location\n",
    "Firstly we need to choose a location for which to detect change. You may either choose one of the locations with pre-assigned variables from the list displayed when running the first cell, or you can choose a new location by selecting 'New Location' which will then prompt you to provide variables of your own when running the second cell. Pre-set locations are the following:\n",
    "- Training Set: Roseau, Dominica (pre-post hurricane Maria); Abricots, Haiti (pre-post hurricane Matthew)\n",
    "- Test Set: Jeremie, Haiti (pre-post hurricane Matthew); Port Salut, Haiti (pre-post hurricane Matthew)\n",
    "- Informal Settlements: Bidonville Killick Stenio Vincent, Port-au-Prince, Haiti (2018 to 2019); Parry Town, Ocho Rios, Jamaica (2018 to 2019)\n",
    "- High Resolution: Hidalgo County, Texas, USA (2016 to 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b6ad9373c14a888f58fe724122585c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Location:', options=(('train - Roseau, Dominica', 0), ('train - Abricots, Haiti', 1), ('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ir_demo_functions as dfn # Import functions from demoFunction.py\n",
    "location = dfn.chooseLocation() # Generate pre-defined location list\n",
    "location # Display location dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfe085a7808457d8957fba5c61679e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show variables', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7a277ea385421d86e483badabbd78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign variables for chosen location - 'updates' caters for 'New Location' variable changing\n",
    "variables, updates = dfn.assignVariables(location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submits input variables for new location (if not new location - no action)\n",
    "variables, updates = dfn.submitNewLocation(variables, updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "<a id='visualiseImagery'></a>\n",
    "## 1 - Visualise Imagery\n",
    "We'll start by displaying before and after images for the chosen location. Two pointers here:\n",
    "- You'll need to click the magic markers below the map to scale the imagery band colours properly. You can also untick the 'After' box to toggle between pre and post disaster.\n",
    "- If you have defined a new location and no imagery appears for your location, try increasing the cloud fraction, but check this does not lead to overly cloudy images which may affect detection performance. Alternatively try changing or widening the requested dates, it is not uncommon to span several months for a good image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4789e6868449bdbd12055c073828ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create map with before and after images for specified location\n",
    "dfn.beforeAfterImages(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id='thresholding'></a>\n",
    "## 2 - Detect Change - Ratio Thresholding\n",
    "Next, let's take the logarithmic ratio of images for selected bands and display detected change superimposed on the image for time 2. Beneath the plot is a slider allowing you to vary the thresholds within which we are detecting change. If damage assessment data is available for the location this will be overlayed for a qualitative comparison.\n",
    "\n",
    "> The optimal threshold interval for detecting building change has been determined as 0.01-0.1. However, due to differences in lighting between repeat images this may need adjsuted according to location. As the ratio is logarithmic, if the second image is considerably darker than the first, the appropriate thresholding may even be negative.\n",
    "\n",
    "Detection interval equation for RGB (red, green and blue bands) where, for example, r1 denotes pixel value for red band at time 1:  $ threshold < \\log\\left(\\frac{r2}{r1} \\times \\frac{b2}{b1} \\times \\frac{g2}{g1}\\right) < cap  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edbb446b1ca46448db4da70780e6c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jup…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e7bb1be6ee49b18d7e409065439fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(0.001, 0.1), description='Filter ratios', max=0.5, min=-0.5, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run box below to display updated detection result\n"
     ]
    }
   ],
   "source": [
    "# Function to detect change through thresholding for location\n",
    "plotVars, variables = dfn.thresholding(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-plot detected change according to slider values\n",
    "plotVars = dfn.plotChange(plotVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may observe 2 main limitations with this method.\n",
    "- Lack of small scale change detections due to 10x10m resolution of Sentinel Imagery. Try re-running the notebook selecting the high resolution location to see what is possible where 1x1m resolution is available.\n",
    "- Sensitivity of thresholding to image lighting and changes in areas other than buildings, due to effect on ratio values. If threshold is unadjusted or mask is not applied to ocean this leads to false detections. To mitigate this limitation we trained a [classifier](#classifier) in the next section to recognise the evidence of damage buildings within the image ratio rather than relying on simple thresholding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "<a id='classifier'></a>\n",
    "## 3 - Detect Change - Ratio Classifier\n",
    "To avoid the drawbacks of thresholding we trained a Convolutional Neural Network (CNN) with a [U-Net](https://arxiv.org/abs/1505.04597) architecture to identify building change from the pixel ratios between before/after Sentinel-2 imagery. This model evaluates change per 'image tile' of which there will be many within your area of interest. Therefore, first let's draw an adjustable polygon over the desired area. Then, each corresponding tile will individually be fed in to the model for assessing change detection. Bare in mind the larger the area the longer it will take to run the model for that area.\n",
    "> One could question the decision not to just increase tilesize. However not only does this method make the evaluation area more flexible, but also the model does not cater well for tile sizes larger than that for which it was trained due to the input layer structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb8de9b1f33489b9718906fb6e34b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m3, testPoly = dfn.drawPolygon(variables) # Get map upon which to draw polygon for assessment\n",
    "m3 # Display map - When adjusting polygon please maintain geometry (e.g. bottom left as bottom left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Latitude Rows:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Longitude Columns:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles requested: 4 . Approximately 32 seconds on 16GB RAM.\n",
      "\n",
      "Job ID: dc6e4adaac3656745bccbbe033967d0e54811878ca2466f9\n",
      "[######] | Steps: 93/93 | Stage: SUCCEEDED                                    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  50%|█████     | 1/2 [00:08<00:08,  8.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 575a039608708a1f971baf8702c2632be241d0e1e777fbbd\n",
      "[######] | Steps: 93/93 | Stage: SUCCEEDED                                    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns: 100%|██████████| 2/2 [00:15<00:00,  7.86s/it]\u001b[A\n",
      "Latitude Rows:  50%|█████     | 1/2 [00:15<00:15, 15.73s/it]\n",
      "Longitude Columns:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 70e608531777822d7addc61298ceb1d5dbc96e130b40c017\n",
      "[######] | Steps: 93/93 | Stage: SUCCEEDED                                    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns:  50%|█████     | 1/2 [00:07<00:07,  7.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 9605d45615c69ed3ddd3de67e802b3c895b2282b92d09932\n",
      "[######] | Steps: 93/93 | Stage: SUCCEEDED                                    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitude Columns: 100%|██████████| 2/2 [00:15<00:00,  8.00s/it]\u001b[A\n",
      "Latitude Rows: 100%|██████████| 2/2 [00:31<00:00, 15.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# Detect change for all tiles at least partly within polygon\n",
    "classified, variables = dfn.classifyDamage(testPoly, variables, m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "<a id='evaluate'></a>\n",
    "## 4 - Evaluate Methods Against Ground Data\n",
    "After qualitatively assessing the ratio method's performance in the previous section, we will now quantify the accuracy of our methods for detecting building damage against Copernicus EMS post-disaster damage assessments where available.\n",
    "\n",
    "Accuracy is determined by evaluating the correspondance between detected changed pixels and damaged building footprints. The metrics are as follows:\n",
    "- Precision (proportion of damage detected): $P = \\frac{True Positives}{True Positives + False Positives}$\n",
    "- Recall (proportion of detections corresponding to damage): $R = \\frac{True Positives}{True Positives + False Negatives}$\n",
    "- F1 Score: $F1 = 2x\\frac{P*R}{P+R}$\n",
    "\n",
    "We will first plot a map evaluating thresholding accuracy, and then for classifier accuracy. Assessing classifier accuracy or accuracy for a smaller area will be much faster.\n",
    "\n",
    "### Thresholding Accuracy\n",
    "Evaluation time increases with number of pixels having detected change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting detections from image for evaluation.\n",
      "\n",
      "Job ID: 1a18fc6c4c3adaed7c6bec2f4358b4ed3a570ece1f46e635\n",
      "[######] | Steps: 107/107 | Stage: SUCCEEDED                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2038it [00:03, 566.76it/s]\n",
      "Pixels evaluated:   0%|          | 6/2006 [00:00<00:40, 49.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed pixels: 2006 \n",
      "Damaged buildings: 392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pixels evaluated: 100%|██████████| 2006/2006 [00:43<00:00, 46.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5535714285714286 \n",
      "Recall: 0.36839481555333997 \n",
      "F1 score: 0.4423867915419523\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a980574475407082f18c4f2b3cfc8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function evaluating thresholding accuracy from detected changes in section 2\n",
    "dfn.thresholdingAccuracy(plotVars,variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/300 [00:00<00:02, 132.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed pixels: 300 \n",
      "Damaged buildings: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:02<00:00, 133.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7333333333333333 \n",
      "Recall: 0.9333333333333333 \n",
      "F1 score: 0.8213333333333334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b39dfec515d4144a64e393746ff7b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function evaluating classifier accuracy from detected changes in section 3\n",
    "dfn.classifierAccuracy(classified,variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for checking out the image ratio demo! Remember to have a look at the individual [thresholding](./thresholding.ipynb) and [unet_classifer](./unet_classifier.ipynb) notebooks to re-train models or take the analysis further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------- END ------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
