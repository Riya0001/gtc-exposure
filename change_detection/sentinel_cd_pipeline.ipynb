{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change detection for satellite imagery using weights trained on FCN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "# Sentinel location\n",
    "locName = 'roseau'\n",
    "lat, long = 18.4665, -66.1057\n",
    "mzoom = 15\n",
    "dmgAss = \"/home/jovyan/gtc-exposure/change_detection/ratio_attempt/dominicaDamage.geojson\"\n",
    "imgColl, cloudFraction = \"sentinel-2:L1C\", 0.06\n",
    "bandNum = 1 # 0-[r,g,b], 1-[r,g,b,nir], 2-[r,g,b,cloud-mask,red-edge-2,red-edge-3,red-edge-4,nir,swir1,swir2]\n",
    "imgNum = 2 # Number of image dates\n",
    "img_st, img_end = ['2017-08-15','2017-10-01'], ['2017-09-15','2017-11-01'] \n",
    "tifResolution, tifTilesize, tifPad = 10, 256, 0\n",
    "\n",
    "# Data storage\n",
    "dataPath = \"/home/jovyan/OSCD/new/\"\n",
    "\n",
    "# Model specifications\n",
    "LOAD_TRAINED = True\n",
    "newTest = True # False - Add to test files, True - Only test on current area\n",
    "TYPE = bandNum\n",
    "modelWeights = '/home/jovyan/gtc-exposure/change_detection/net_final.pth.tar'\n",
    "PATH_TO_TRAIN = \"/home/jovyan/OSCD/onera/\"\n",
    "FP_MODIFIER = 1 # Tuning parameter, use 1 if unsure\n",
    "BATCH_SIZE = 8\n",
    "PATCH_SIDE = 64\n",
    "NORMALISE_IMGS = True\n",
    "TRAIN_STRIDE = int(PATCH_SIDE/2) - 1\n",
    "DATA_AUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import IPython\n",
    "import ipywidgets\n",
    "import ipyleaflet\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.4.0\n"
     ]
    }
   ],
   "source": [
    "# import PyTorch and model functions\n",
    "#PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "# Models\n",
    "from models.unet import Unet\n",
    "# from siamunet_conc import SiamUnet_conc\n",
    "# from siamunet_diff import SiamUnet_diff\n",
    "# from fresunet import FresUNet\n",
    "# from smallunet import SmallUnet\n",
    "# from smallunet_attempt import Unet\n",
    "\n",
    "import descarteslabs as dl\n",
    "import descarteslabs.workflows as wf\n",
    "import importlib\n",
    "import tifffile\n",
    "import imagecodecs\n",
    "from shutil import copyfile\n",
    "from skimage import io\n",
    "from tqdm import tqdm as tqdm\n",
    "from pandas import read_csv\n",
    "from math import floor, ceil, sqrt, exp\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "print('PyTorch version',torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTS OK\n"
     ]
    }
   ],
   "source": [
    "# import custom functions from utils file\n",
    "from utils_cd import generate_tiff_from_polygons, save_test_results, test\n",
    "\n",
    "print('IMPORTS OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time separated imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dc9602d18d4a518931d87a6befd3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = wf.interactive.MapApp()\n",
    "m.center = (lat, long)\n",
    "m.zoom = mzoom\n",
    "types = [\"red green blue\",\"red green blue nir\",\"red green blue cloud-mask red-edge-2 red-edge-3 red-edge-4 nir swir1 swir2\"]\n",
    "bands = types[bandNum]\n",
    "\n",
    "for i in range(imgNum):\n",
    "    img = wf.ImageCollection.from_id(imgColl,start_datetime=img_st[i], end_datetime=img_end[i]).pick_bands(bands)\n",
    "    img = img.filter(lambda img: img.properties[\"cloud_fraction\"] <= cloudFraction)\n",
    "    img_msk = img.map(lambda img: img.mask(img.pick_bands('cloud-mask')==1)) if bandNum > 1 else img\n",
    "    mos = (img_msk.mosaic().pick_bands(\"red green blue\"))\n",
    "    mos.visualize('Image '+str(i+1), map=m)\n",
    "\n",
    "with open(dmgAss) as f: dmg = json.load(f)\n",
    "dmg_geojson = ipyleaflet.GeoJSON(data=dmg,\n",
    "                   style={\"color\": \"red\", \"lineOpacity\": 0.5, \"fillOpacity\": 0.1},\n",
    "                   hover_style={\"fillOpacity\": 0.1})\n",
    "\n",
    "m.add_layer(dmg_geojson)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create .tiff files from Sentinel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tiff files containing all bands for each tile\n",
    "for i in range(imgNum):\n",
    "    out = dataPath+locName+\"/imgs_\"+str(i+1)+\"/\"\n",
    "    generate_tiff_from_polygons(dmgAss,\n",
    "                    products=imgColl,\n",
    "                    bands=bands,\n",
    "                    resolution=tifResolution,\n",
    "                    tilesize=tifTilesize,\n",
    "                    pad=tifPad,\n",
    "                    start_datetime=img_st[i],\n",
    "                    end_datetime=img_end[i],\n",
    "                    out_folder=out,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: /home/jovyan/OSCD/new/roseau_0/cm/cm.png is a low contrast image\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: /home/jovyan/OSCD/new/roseau_1/cm/cm.png is a low contrast image\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: /home/jovyan/OSCD/new/roseau_2/cm/cm.png is a low contrast image\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: /home/jovyan/OSCD/new/roseau_3/cm/cm.png is a low contrast image\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Separate bands from tiff files and place in correct folder structure for evaluation\n",
    "file = open(dataPath+'test.txt','w') if newTest else open(dataPath+'test.txt','a') # Open test.txt file\n",
    "bandNumbers = [[4,3,2], [4,3,2,8], [4,3,2,1,5,6,7,8,9,10]] # Set appropriate band numbers for Sentinel bands\n",
    "\n",
    "for i in range(len([name for name in os.listdir(out) if 'image' in name])): # Loop over tile number from location\n",
    "    imgFolder = dataPath+locName+'_'+str(i) # Create directory for each tile in location\n",
    "    if not os.path.exists(imgFolder): os.makedirs(imgFolder)\n",
    "    file.write(','+locName+'_'+str(i)) if i>0 else file.write(locName+'_'+str(i)) # Write tile number to locations to be tested\n",
    "     \n",
    "    if not os.path.exists(imgFolder+\"/cm/\"): os.makedirs(imgFolder+\"/cm/\")\n",
    "    targDest = imgFolder+\"/cm/\"+locName+'_'+str(i)+\"-cm.tif\"\n",
    "    copyfile(dataPath+locName+\"/imgs_1/target_\"+str(i)+\".tiff\", targDest) # Copy target file to tile directory\n",
    "    imgconv = io.imread(targDest)\n",
    "    io.imsave(imgFolder+\"/cm/cm.png\", imgconv)\n",
    "    \n",
    "    for j in range(imgNum): # Loop over time points for images\n",
    "        img = io.imread(dataPath+locName+\"/imgs_\"+str(j+1)+\"/\"+'image_'+str(i)+'.tiff')\n",
    "        dest = imgFolder+\"/imgs_\"+str(j+1)\n",
    "        if not os.path.exists(dest): os.makedirs(dest)\n",
    "        \n",
    "        for k in range(img.shape[2]): # Loop over bands in each image\n",
    "            io.imsave(dest+\"/B\"+\"{0:0=2d}\".format(bandNumbers[bandNum][k])+\".tif\",img[:,:,k])\n",
    "        \n",
    "file.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in new dataset (need to run Change Detection class at bottom of notebook first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 74.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roseau_0\n",
      "(256, 256, 4) (256, 256, 4)\n",
      "roseau_1\n",
      "(256, 256, 4) (256, 256, 4)\n",
      "roseau_2\n",
      "(256, 256, 4) (256, 256, 4)\n",
      "roseau_3\n",
      "(256, 256, 4) (256, 256, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load in new dataset\n",
    "new_dataset = ChangeDetectionDataset(dataPath, train = False, stride = TRAIN_STRIDE)\n",
    "new_loader = DataLoader(new_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [00:00<00:00, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aguasclaras\n",
      "(471, 525, 4) (471, 525, 4)\n",
      "bercy\n",
      "(395, 360, 4) (395, 360, 4)\n",
      "bordeaux\n",
      "(517, 461, 4) (517, 461, 4)\n",
      "nantes\n",
      "(522, 582, 4) (522, 582, 4)\n",
      "paris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6/14 [00:00<00:00, 24.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 390, 4) (408, 390, 4)\n",
      "rennes\n",
      "(339, 563, 4) (339, 563, 4)\n",
      "saclay_e\n",
      "(639, 688, 4) (631, 679, 4)\n",
      "abudhabi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8/14 [00:00<00:00, 17.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 785, 4) (795, 782, 4)\n",
      "cupertino\n",
      "(1015, 788, 4) (1015, 788, 4)\n",
      "pisa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [00:00<00:00, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(776, 718, 4) (776, 718, 4)\n",
      "beihai\n",
      "(902, 772, 4) (902, 772, 4)\n",
      "hongkong\n",
      "(695, 540, 4) (693, 538, 4)\n",
      "beirut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1180, 1070, 4) (1180, 1070, 4)\n",
      "mumbai\n",
      "(858, 557, 4) (858, 557, 4)\n",
      "Trained parameters  1350866\n",
      "LOAD OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load in pre-trained model\n",
    "train_dataset, weights, net, net_name, criterion, params = init_network(DATA_AUG, PATH_TO_TRAIN, TRAIN_STRIDE, TYPE)\n",
    "print('Trained parameters ', params)\n",
    "\n",
    "if LOAD_TRAINED:\n",
    "    net.load_state_dict(torch.load(modelWeights, map_location=torch.device('cpu')),strict=False) #torch.load('/home/jovyan/gtc-exposure/change_detection/net_final.pth.tar'))\n",
    "    print('LOAD OK')\n",
    "else:\n",
    "    t_start = time.time()\n",
    "    out_dic = train()\n",
    "    t_end = time.time()\n",
    "    print(out_dic)\n",
    "    print('Elapsed time:')\n",
    "    print(t_end - t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/home/jovyan/gtc-exposure/change_detection/utils_cd.py:232: UserWarning: ./results/FC-EF-roseau_0.png is a low contrast image\n",
      "  io.imsave(f'./results/{net_name}-{name}.png',I)\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.30it/s]/home/jovyan/gtc-exposure/change_detection/utils_cd.py:232: UserWarning: ./results/FC-EF-roseau_1.png is a low contrast image\n",
      "  io.imsave(f'./results/{net_name}-{name}.png',I)\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      " 50%|█████     | 2/4 [00:00<00:00,  2.21it/s]/home/jovyan/gtc-exposure/change_detection/utils_cd.py:232: UserWarning: ./results/FC-EF-roseau_2.png is a low contrast image\n",
      "  io.imsave(f'./results/{net_name}-{name}.png',I)\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  2.34it/s]/home/jovyan/gtc-exposure/change_detection/utils_cd.py:232: UserWarning: ./results/FC-EF-roseau_3.png is a low contrast image\n",
      "  io.imsave(f'./results/{net_name}-{name}.png',I)\n",
      "Lossy conversion from int64 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.611487865447998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate .png images of detection -> Generates .png results for each tile\n",
    "t_start = time.time()\n",
    "save_test_results(new_dataset, net, net_name)\n",
    "t_end = time.time()\n",
    "print('Elapsed time: {}'.format(t_end - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_accuracy': [83.94007110595703, 12.394295692443848],\n",
      " 'dice': 0.05565897244973939,\n",
      " 'kappa': -0.016910603493125852,\n",
      " 'net_accuracy': 80.64804077148438,\n",
      " 'net_loss': 1.478447437286377,\n",
      " 'precision': 0.03588746459263527,\n",
      " 'recall': 0.12394296136627425}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assess accuracy\n",
    "results = test(new_dataset, net, criterion)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Detection Dataset class -> could be put in other file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTILS OK\n"
     ]
    }
   ],
   "source": [
    "# Functions\n",
    "\n",
    "def adjust_shape(I, s):\n",
    "    \"\"\"Adjust shape of grayscale image I to s.\"\"\"\n",
    "    \n",
    "    # crop if necesary\n",
    "    I = I[:s[0],:s[1]]\n",
    "    si = I.shape\n",
    "    \n",
    "    # pad if necessary \n",
    "    p0 = max(0,s[0] - si[0])\n",
    "    p1 = max(0,s[1] - si[1])\n",
    "    \n",
    "    return np.pad(I,((0,p0),(0,p1)),'edge')\n",
    "    \n",
    "\n",
    "def read_sentinel_img(path):\n",
    "    \"\"\"Read cropped Sentinel-2 image: RGB bands.\"\"\"\n",
    "    im_name = os.listdir(path)[0][:-7]\n",
    "    r = io.imread(path + im_name + \"B04.tif\")\n",
    "    g = io.imread(path + im_name + \"B03.tif\")\n",
    "    b = io.imread(path + im_name + \"B02.tif\")\n",
    "    \n",
    "    I = np.stack((r,g,b),axis=2).astype('float')\n",
    "    \n",
    "    if NORMALISE_IMGS:\n",
    "        I = (I - I.mean()) / I.std()\n",
    "\n",
    "    return I\n",
    "\n",
    "def read_sentinel_img_4(path):\n",
    "    \"\"\"Read cropped Sentinel-2 image: RGB and NIR bands.\"\"\"\n",
    "    im_name = os.listdir(path)[0][:-7]\n",
    "    r = io.imread(path + im_name + \"B04.tif\")\n",
    "    g = io.imread(path + im_name + \"B03.tif\")\n",
    "    b = io.imread(path + im_name + \"B02.tif\")\n",
    "    nir = io.imread(path + im_name + \"B08.tif\")\n",
    "    \n",
    "    I = np.stack((r,g,b,nir),axis=2).astype('float')\n",
    "    \n",
    "    I = I.reshape(I.shape[0],I.shape[1],I.shape[2])\n",
    "    \n",
    "    if NORMALISE_IMGS:\n",
    "        I = (I - I.mean()) / I.std()\n",
    "\n",
    "    return I\n",
    "\n",
    "def read_sentinel_img_leq20(path):\n",
    "    \"\"\"Read cropped Sentinel-2 image: bands with resolution less than or equals to 20m.\"\"\"\n",
    "    im_name = os.listdir(path)[0][:-7]\n",
    "    \n",
    "    r = io.imread(path + im_name + \"B04.tif\")\n",
    "    s = r.shape\n",
    "    g = io.imread(path + im_name + \"B03.tif\")\n",
    "    b = io.imread(path + im_name + \"B02.tif\")\n",
    "    nir = io.imread(path + im_name + \"B08.tif\")\n",
    "    \n",
    "    ir1 = adjust_shape(zoom(io.imread(path + im_name + \"B05.tif\"),2),s)\n",
    "    ir2 = adjust_shape(zoom(io.imread(path + im_name + \"B06.tif\"),2),s)\n",
    "    ir3 = adjust_shape(zoom(io.imread(path + im_name + \"B07.tif\"),2),s)\n",
    "    nir2 = adjust_shape(zoom(io.imread(path + im_name + \"B8A.tif\"),2),s)\n",
    "    swir2 = adjust_shape(zoom(io.imread(path + im_name + \"B11.tif\"),2),s)\n",
    "    swir3 = adjust_shape(zoom(io.imread(path + im_name + \"B12.tif\"),2),s)\n",
    "    \n",
    "    I = np.stack((r,g,b,nir,ir1,ir2,ir3,nir2,swir2,swir3),axis=2).astype('float')\n",
    "    \n",
    "    if NORMALISE_IMGS:\n",
    "        I = (I - I.mean()) / I.std()\n",
    "\n",
    "    return I\n",
    "\n",
    "def read_sentinel_img_leq60(path):\n",
    "    \"\"\"Read cropped Sentinel-2 image: all bands.\"\"\"\n",
    "    im_name = os.listdir(path)[0][:-7]\n",
    "    \n",
    "    r = io.imread(path + im_name + \"B04.tif\")\n",
    "    s = r.shape\n",
    "    g = io.imread(path + im_name + \"B03.tif\")\n",
    "    b = io.imread(path + im_name + \"B02.tif\")\n",
    "    nir = io.imread(path + im_name + \"B08.tif\")\n",
    "    \n",
    "    ir1 = adjust_shape(zoom(io.imread(path + im_name + \"B05.tif\"),2),s)\n",
    "    ir2 = adjust_shape(zoom(io.imread(path + im_name + \"B06.tif\"),2),s)\n",
    "    ir3 = adjust_shape(zoom(io.imread(path + im_name + \"B07.tif\"),2),s)\n",
    "    nir2 = adjust_shape(zoom(io.imread(path + im_name + \"B8A.tif\"),2),s)\n",
    "    swir2 = adjust_shape(zoom(io.imread(path + im_name + \"B11.tif\"),2),s)\n",
    "    swir3 = adjust_shape(zoom(io.imread(path + im_name + \"B12.tif\"),2),s)\n",
    "    \n",
    "    uv = adjust_shape(zoom(io.imread(path + im_name + \"B01.tif\"),6),s)\n",
    "    wv = adjust_shape(zoom(io.imread(path + im_name + \"B09.tif\"),6),s)\n",
    "    swirc = adjust_shape(zoom(io.imread(path + im_name + \"B10.tif\"),6),s)\n",
    "    \n",
    "    I = np.stack((r,g,b,nir,ir1,ir2,ir3,nir2,swir2,swir3,uv,wv,swirc),axis=2).astype('float')\n",
    "    \n",
    "    if NORMALISE_IMGS:\n",
    "        I = (I - I.mean()) / I.std()\n",
    "\n",
    "    return I\n",
    "\n",
    "def read_sentinel_img_trio(path):\n",
    "    \"\"\"Read cropped Sentinel-2 image pair and change map.\"\"\"\n",
    "#     read images\n",
    "    if TYPE == 0:\n",
    "        I1 = read_sentinel_img(path + '/imgs_1/')\n",
    "        I2 = read_sentinel_img(path + '/imgs_2/')\n",
    "    elif TYPE == 1:\n",
    "        I1 = read_sentinel_img_4(path + '/imgs_1/')\n",
    "        I2 = read_sentinel_img_4(path + '/imgs_2/')\n",
    "    elif TYPE == 2:\n",
    "        I1 = read_sentinel_img_leq20(path + '/imgs_1/')\n",
    "        I2 = read_sentinel_img_leq20(path + '/imgs_2/')\n",
    "    elif TYPE == 3:\n",
    "        I1 = read_sentinel_img_leq60(path + '/imgs_1/')\n",
    "        I2 = read_sentinel_img_leq60(path + '/imgs_2/')\n",
    "        \n",
    "    cm = io.imread(path + '/cm/cm.png', as_gray=True) != 0\n",
    "    \n",
    "    # crop if necessary\n",
    "    s1 = I1.shape\n",
    "    s2 = I2.shape\n",
    "    print(s1,s2)\n",
    "    I2 = np.pad(I2,((0, s1[0] - s2[0]), (0, s1[1] - s2[1]), (0,0)),'edge')\n",
    "    \n",
    "    \n",
    "    return I1, I2, cm\n",
    "\n",
    "\n",
    "\n",
    "def reshape_for_torch(I):\n",
    "    \"\"\"Transpose image for PyTorch coordinates.\"\"\"\n",
    "#     out = np.swapaxes(I,1,2)\n",
    "#     out = np.swapaxes(out,0,1)\n",
    "#     out = out[np.newaxis,:]\n",
    "    out = I.transpose((2, 0, 1))\n",
    "    return torch.from_numpy(out)\n",
    "\n",
    "\n",
    "\n",
    "class ChangeDetectionDataset(Dataset):\n",
    "    \"\"\"Change Detection dataset class, used for both training and test data.\"\"\"\n",
    "\n",
    "    def __init__(self, path, train = True, patch_side = 96, stride = None, use_all_bands = False, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        # basics\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "        self.patch_side = patch_side\n",
    "        if not stride:\n",
    "            self.stride = 1\n",
    "        else:\n",
    "            self.stride = stride\n",
    "        \n",
    "        if train:\n",
    "            fname = 'train.txt'\n",
    "        else:\n",
    "            fname = 'test.txt'\n",
    "        \n",
    "#         print(path + fname)\n",
    "        self.names = read_csv(path + fname).columns\n",
    "        self.n_imgs = self.names.shape[0]\n",
    "        \n",
    "        n_pix = 0\n",
    "        true_pix = 0\n",
    "        \n",
    "        \n",
    "        # load images\n",
    "        self.imgs_1 = {}\n",
    "        self.imgs_2 = {}\n",
    "        self.change_maps = {}\n",
    "        self.n_patches_per_image = {}\n",
    "        self.n_patches = 0\n",
    "        self.patch_coords = []\n",
    "        for im_name in tqdm(self.names):\n",
    "            # load and store each image\n",
    "            print(im_name)\n",
    "            I1, I2, cm = read_sentinel_img_trio(self.path + im_name)\n",
    "            self.imgs_1[im_name] = reshape_for_torch(I1)\n",
    "            self.imgs_2[im_name] = reshape_for_torch(I2)\n",
    "            self.change_maps[im_name] = cm\n",
    "            \n",
    "            s = cm.shape\n",
    "            n_pix += np.prod(s)\n",
    "            true_pix += cm.sum()\n",
    "            \n",
    "            # calculate the number of patches\n",
    "            s = self.imgs_1[im_name].shape\n",
    "            n1 = ceil((s[1] - self.patch_side + 1) / self.stride)\n",
    "            n2 = ceil((s[2] - self.patch_side + 1) / self.stride)\n",
    "            n_patches_i = n1 * n2\n",
    "            self.n_patches_per_image[im_name] = n_patches_i\n",
    "            self.n_patches += n_patches_i\n",
    "            \n",
    "            # generate path coordinates\n",
    "            for i in range(n1):\n",
    "                for j in range(n2):\n",
    "                    # coordinates in (x1, x2, y1, y2)\n",
    "                    current_patch_coords = (im_name, \n",
    "                                    [self.stride*i, self.stride*i + self.patch_side, self.stride*j, self.stride*j + self.patch_side],\n",
    "                                    [self.stride*(i + 1), self.stride*(j + 1)])\n",
    "                    self.patch_coords.append(current_patch_coords)\n",
    "                    \n",
    "        self.weights = [ FP_MODIFIER * 2 * true_pix / n_pix, 2 * (n_pix - true_pix) / n_pix]   \n",
    "\n",
    "    def get_img(self, im_name):\n",
    "        return self.imgs_1[im_name], self.imgs_2[im_name], self.change_maps[im_name]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_patches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_patch_coords = self.patch_coords[idx]\n",
    "        im_name = current_patch_coords[0]\n",
    "        limits = current_patch_coords[1]\n",
    "        centre = current_patch_coords[2]\n",
    "        \n",
    "        I1 = self.imgs_1[im_name][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        I2 = self.imgs_2[im_name][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        \n",
    "        label = self.change_maps[im_name][limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        label = torch.from_numpy(1*np.array(label)).float()\n",
    "        \n",
    "        sample = {'I1': I1, 'I2': I2, 'label': label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class RandomFlip(object):\n",
    "    \"\"\"Flip randomly the images in a sample.\"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         return\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        I1, I2, label = sample['I1'], sample['I2'], sample['label']\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            I1 =  I1.numpy()[:,:,::-1].copy()\n",
    "            I1 = torch.from_numpy(I1)\n",
    "            I2 =  I2.numpy()[:,:,::-1].copy()\n",
    "            I2 = torch.from_numpy(I2)\n",
    "            label =  label.numpy()[:,::-1].copy()\n",
    "            label = torch.from_numpy(label)\n",
    "\n",
    "        return {'I1': I1, 'I2': I2, 'label': label}\n",
    "\n",
    "class RandomRot(object):\n",
    "    \"\"\"Rotate randomly the images in a sample.\"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         return\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        I1, I2, label = sample['I1'], sample['I2'], sample['label']\n",
    "        \n",
    "        n = random.randint(0, 3)\n",
    "        if n:\n",
    "            I1 =  sample['I1'].numpy()\n",
    "            I1 = np.rot90(I1, n, axes=(1, 2)).copy()\n",
    "            I1 = torch.from_numpy(I1)\n",
    "            I2 =  sample['I2'].numpy()\n",
    "            I2 = np.rot90(I2, n, axes=(1, 2)).copy()\n",
    "            I2 = torch.from_numpy(I2)\n",
    "            label =  sample['label'].numpy()\n",
    "            label = np.rot90(label, n, axes=(0, 1)).copy()\n",
    "            label = torch.from_numpy(label)\n",
    "\n",
    "        return {'I1': I1, 'I2': I2, 'label': label}\n",
    "\n",
    "\"\"\"\n",
    "Network initialisation function\n",
    "\"\"\"\n",
    "# Initialise network\n",
    "def init_network(DATA_AUG, PATH_TO_TRAIN, TRAIN_STRIDE, TYPE):\n",
    "    if DATA_AUG:\n",
    "        data_transform = tr.Compose([RandomFlip(), RandomRot()])\n",
    "    else:\n",
    "        data_transform = None\n",
    "    train_dataset = ChangeDetectionDataset(PATH_TO_TRAIN, train = True, stride = TRAIN_STRIDE, transform=data_transform)\n",
    "    weights = torch.FloatTensor(train_dataset.weights)\n",
    "\n",
    "    # 0-RGB | 1-RGBIr | 2-All bands s.t. resulution <= 20m | 3-All bands\n",
    "\n",
    "    if TYPE == 0:\n",
    "        net, net_name = Unet(2*3, 2), 'FC-EF'\n",
    "    #     net, net_name = Unet(2*3, 2), 'FC-EF'\n",
    "    #     net, net_name = SiamUnet_conc(3, 2), 'FC-Siam-conc'\n",
    "    #     net, net_name = SiamUnet_diff(3, 2), 'FC-Siam-diff'#\n",
    "    #     net, net_name = FresUNet(2*3, 2), 'FresUNet'\n",
    "    elif TYPE == 1:\n",
    "    #     net, net_name = SmallUnet(2*4, 2), 'FC-EF'\n",
    "        net, net_name = Unet(2*4, 2), 'FC-EF'\n",
    "    #     net, net_name = SiamUnet_conc(4, 2), 'FC-Siam-conc'\n",
    "    #     net, net_name = SiamUnet_diff(4, 2), 'FC-Siam-diff'\n",
    "    #     net, net_name = FresUNet(2*4, 2), 'FresUNet'\n",
    "    elif TYPE == 2:\n",
    "        net, net_name = SmallUnet(2*10, 2), 'FC-EF'\n",
    "    #     net, net_name = Unet(2*10, 2), 'FC-EF'\n",
    "    #     net, net_name = SiamUnet_conc(10, 2), 'FC-Siam-conc'\n",
    "    #     net, net_name = SiamUnet_diff(10, 2), 'FC-Siam-diff'\n",
    "    #     net, net_name = FresUNet(2*10, 2), 'FresUNet'\n",
    "    elif TYPE == 3:\n",
    "        net, net_name = SmallUnet(2*13, 2), 'FC-EF'\n",
    "    #     net, net_name = Unet(2*13, 2), 'FC-EF'\n",
    "    #     net, net_name = SiamUnet_conc(13, 2), 'FC-Siam-conc'\n",
    "    #     net, net_name = SiamUnet_diff(13, 2), 'FC-Siam-diff'\n",
    "    #     net, net_name = FresUNet(2*13, 2), 'FresUNet'\n",
    "\n",
    "    criterion = nn.NLLLoss(weight=weights) # to be used with logsoftmax output\n",
    "    params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    \n",
    "    return train_dataset, weights, net, net_name, criterion, params\n",
    "    \n",
    "print('UTILS OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Fully Convolutional Networks for Change Detection code for training the network presented in the paper:\n",
    "\n",
    "```\n",
    "Daudt, R.C., Le Saux, B. and Boulch, A., 2018, October. Fully convolutional siamese networks for change detection. In 2018 25th IEEE International Conference on Image Processing (ICIP) (pp. 4063-4067). IEEE.\n",
    "```\n",
    "\n",
    "Code uses the OSCD dataset:\n",
    "\n",
    "```\n",
    "Daudt, R.C., Le Saux, B., Boulch, A. and Gousseau, Y., 2018, July. Urban change detection for multispectral earth observation using convolutional neural networks. In IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium (pp. 2115-2118). IEEE.\n",
    "```\n",
    "\n",
    "\n",
    "FresUNet architecture from paper:\n",
    "\n",
    "```\n",
    "Daudt, R.C., Le Saux, B., Boulch, A. and Gousseau, Y., 2019. Multitask learning for large-scale semantic change detection. Computer Vision and Image Understanding, 187, p.102783.\n",
    "```\n",
    "\n",
    "Please consider all relevant papers if you use this code.\n",
    "\n",
    "Rodrigo Daudt\n",
    "rcdaudt.github.io\n",
    "rodrigo.daudt@onera.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
